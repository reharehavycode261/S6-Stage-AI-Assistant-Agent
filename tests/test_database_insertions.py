# -*- coding: utf-8 -*-
"""
Script de test pour valider les insertions dans toutes les tables de la base de donnÃ©es.
"""

from __future__ import annotations

import asyncio
import asyncpg
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
import sys
import os

# Ajouter le rÃ©pertoire parent au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from config.settings import get_settings
from services.database_persistence_service import db_persistence
from services.human_validation_service import HumanValidationService
from services.system_config_service import system_config_service
from models.schemas import HumanValidationRequest, HumanValidationResponse, HumanValidationStatus
from utils.logger import get_logger

logger = get_logger(__name__)


class DatabaseInsertionTester:
    """Testeur pour valider les insertions dans toutes les tables."""
    
    def __init__(self):
        self.settings = get_settings()
        self.db_pool = None  # type: Optional[asyncpg.Pool]
        self.test_results = {}
        self.test_ids = {}  # Pour stocker les IDs crÃ©Ã©s pendant les tests
    
    async def initialize(self):
        """Initialise les connexions aux services."""
        logger.info("ğŸ”§ Initialisation des services...")
        
        # Initialiser le pool de base de donnÃ©es principal
        self.db_pool = await asyncpg.create_pool(
            self.settings.database_url,
            min_size=2,
            max_size=10,
            command_timeout=60
        )
        
        # Initialiser les services
        await db_persistence.initialize()
        
        logger.info("âœ… Services initialisÃ©s")
    
    async def cleanup(self):
        """Nettoie les connexions."""
        if self.db_pool:
            await self.db_pool.close()
        await db_persistence.close()
        logger.info("ğŸ§¹ Nettoyage terminÃ©")
    
    async def test_tasks_table(self) -> bool:
        """Teste l'insertion dans la table tasks."""
        logger.info("ğŸ“‹ Test: table tasks")
        try:
            test_payload = {
                "pulseId": 999888777,
                "boardId": 123456,
                "pulseName": "Test Task - Database Insertion",
                "columnValues": {
                    "description": {"text": "Test de crÃ©ation de tÃ¢che"},
                    "priority": {"text": "high"},
                    "repository_url": {"text": "https://github.com/test/repo"}
                }
            }
            
            task_id = await db_persistence.create_task_from_monday(test_payload)
            self.test_ids['task_id'] = task_id
            
            if task_id:
                logger.info(f"âœ… tasks: Task crÃ©Ã©e avec ID {task_id}")
                self.test_results['tasks'] = True
                return True
            else:
                logger.error("âŒ tasks: Ã‰chec crÃ©ation task")
                self.test_results['tasks'] = False
                return False
                
        except Exception as e:
            logger.error(f"âŒ tasks: Exception - {e}")
            self.test_results['tasks'] = False
            return False
    
    async def test_task_runs_table(self) -> bool:
        """Teste l'insertion dans la table task_runs."""
        logger.info("ğŸ“‹ Test: table task_runs")
        try:
            task_id = self.test_ids.get('task_id')
            if not task_id:
                logger.warning("âš ï¸ task_runs: Pas de task_id disponible, crÃ©ation d'une task")
                await self.test_tasks_table()
                task_id = self.test_ids.get('task_id')
            
            run_id = await db_persistence.start_task_run(
                task_id=task_id,
                celery_task_id=f"test_celery_{datetime.now().timestamp()}",
                ai_provider="claude"
            )
            self.test_ids['run_id'] = run_id
            
            if run_id:
                logger.info(f"âœ… task_runs: Run crÃ©Ã© avec ID {run_id}")
                self.test_results['task_runs'] = True
                return True
            else:
                logger.error("âŒ task_runs: Ã‰chec crÃ©ation run")
                self.test_results['task_runs'] = False
                return False
                
        except Exception as e:
            logger.error(f"âŒ task_runs: Exception - {e}")
            self.test_results['task_runs'] = False
            return False
    
    async def test_run_steps_table(self) -> bool:
        """Teste l'insertion dans la table run_steps."""
        logger.info("ğŸ“‹ Test: table run_steps")
        try:
            run_id = self.test_ids.get('run_id')
            if not run_id:
                logger.warning("âš ï¸ run_steps: Pas de run_id disponible, crÃ©ation d'un run")
                await self.test_task_runs_table()
                run_id = self.test_ids.get('run_id')
            
            step_id = await db_persistence.create_run_step(
                task_run_id=run_id,
                node_name="test_node",
                step_order=1,
                input_data={"test": "data"}
            )
            self.test_ids['step_id'] = step_id
            
            if step_id:
                # ComplÃ©ter le step
                await db_persistence.complete_run_step(
                    step_id=step_id,
                    status="completed",
                    output_data={"result": "success"}
                )
                logger.info(f"âœ… run_steps: Step crÃ©Ã© et complÃ©tÃ© avec ID {step_id}")
                self.test_results['run_steps'] = True
                return True
            else:
                logger.error("âŒ run_steps: Ã‰chec crÃ©ation step")
                self.test_results['run_steps'] = False
                return False
                
        except Exception as e:
            logger.error(f"âŒ run_steps: Exception - {e}")
            self.test_results['run_steps'] = False
            return False
    
    async def test_ai_interactions_table(self) -> bool:
        """Teste l'insertion dans la table ai_interactions."""
        logger.info("ğŸ“‹ Test: table ai_interactions")
        try:
            step_id = self.test_ids.get('step_id')
            if not step_id:
                logger.warning("âš ï¸ ai_interactions: Pas de step_id disponible, crÃ©ation d'un step")
                await self.test_run_steps_table()
                step_id = self.test_ids.get('step_id')
            
            interaction_id = await db_persistence.log_ai_interaction(
                run_step_id=step_id,
                ai_provider="claude",
                model="claude-3-5-sonnet-20241022",
                prompt="Test prompt",
                response="Test response",
                token_usage={"prompt_tokens": 10, "completion_tokens": 20},
                latency_ms=1500
            )
            
            if interaction_id:
                logger.info(f"âœ… ai_interactions: Interaction crÃ©Ã©e avec ID {interaction_id}")
                self.test_results['ai_interactions'] = True
                return True
            else:
                logger.error("âŒ ai_interactions: Ã‰chec crÃ©ation interaction")
                self.test_results['ai_interactions'] = False
                return False
                
        except Exception as e:
            logger.error(f"âŒ ai_interactions: Exception - {e}")
            self.test_results['ai_interactions'] = False
            return False
    
    async def test_ai_code_generations_table(self) -> bool:
        """Teste l'insertion dans la table ai_code_generations."""
        logger.info("ğŸ“‹ Test: table ai_code_generations")
        try:
            run_id = self.test_ids.get('run_id')
            if not run_id:
                logger.warning("âš ï¸ ai_code_generations: Pas de run_id disponible, crÃ©ation d'un run")
                await self.test_task_runs_table()
                run_id = self.test_ids.get('run_id')
            
            gen_id = await db_persistence.log_code_generation(
                task_run_id=run_id,
                provider="claude",
                model="claude-3-5-sonnet-20241022",
                generation_type="initial",
                prompt="Generate a hello world function",
                generated_code="def hello(): print('Hello World')",
                tokens_used=50,
                response_time_ms=2000,
                cost_estimate=0.002,
                files_modified=["test.py"]
            )
            
            if gen_id:
                logger.info(f"âœ… ai_code_generations: GÃ©nÃ©ration crÃ©Ã©e avec ID {gen_id}")
                self.test_results['ai_code_generations'] = True
                return True
            else:
                logger.error("âŒ ai_code_generations: Ã‰chec crÃ©ation gÃ©nÃ©ration")
                self.test_results['ai_code_generations'] = False
                return False
                
        except Exception as e:
            logger.error(f"âŒ ai_code_generations: Exception - {e}")
            self.test_results['ai_code_generations'] = False
            return False
    
    async def test_test_results_table(self) -> bool:
        """Teste l'insertion dans la table test_results."""
        logger.info("ğŸ“‹ Test: table test_results")
        try:
            run_id = self.test_ids.get('run_id')
            if not run_id:
                logger.warning("âš ï¸ test_results: Pas de run_id disponible, crÃ©ation d'un run")
                await self.test_task_runs_table()
                run_id = self.test_ids.get('run_id')
            
            test_id = await db_persistence.log_test_results(
                task_run_id=run_id,
                passed=True,
                status="passed",
                tests_total=10,
                tests_passed=10,
                tests_failed=0,
                tests_skipped=0,
                coverage_percentage=85.5,
                pytest_report={"summary": "All tests passed"},
                duration_seconds=30
            )
            
            if test_id:
                logger.info(f"âœ… test_results: RÃ©sultats de tests crÃ©Ã©s avec ID {test_id}")
                self.test_results['test_results'] = True
                return True
            else:
                logger.error("âŒ test_results: Ã‰chec crÃ©ation rÃ©sultats tests")
                self.test_results['test_results'] = False
                return False
                
        except Exception as e:
            logger.error(f"âŒ test_results: Exception - {e}")
            self.test_results['test_results'] = False
            return False
    
    async def test_pull_requests_table(self) -> bool:
        """Teste l'insertion dans la table pull_requests."""
        logger.info("ğŸ“‹ Test: table pull_requests")
        try:
            task_id = self.test_ids.get('task_id')
            run_id = self.test_ids.get('run_id')
            
            if not task_id or not run_id:
                logger.warning("âš ï¸ pull_requests: Pas de task_id ou run_id, crÃ©ation...")
                if not task_id:
                    await self.test_tasks_table()
                    task_id = self.test_ids.get('task_id')
                if not run_id:
                    await self.test_task_runs_table()
                    run_id = self.test_ids.get('run_id')
            
            pr_id = await db_persistence.create_pull_request(
                task_id=task_id,
                task_run_id=run_id,
                github_pr_number=123,
                github_pr_url="https://github.com/test/repo/pull/123",
                pr_title="Test PR",
                pr_description="Test description",
                head_sha="abc123def456",
                base_branch="main",
                feature_branch="test-branch"
            )
            
            if pr_id:
                logger.info(f"âœ… pull_requests: PR crÃ©Ã©e avec ID {pr_id}")
                self.test_results['pull_requests'] = True
                return True
            else:
                logger.error("âŒ pull_requests: Ã‰chec crÃ©ation PR")
                self.test_results['pull_requests'] = False
                return False
                
        except Exception as e:
            logger.error(f"âŒ pull_requests: Exception - {e}")
            self.test_results['pull_requests'] = False
            return False
    
    async def test_performance_metrics_table(self) -> bool:
        """Teste l'insertion dans la table performance_metrics."""
        logger.info("ğŸ“‹ Test: table performance_metrics")
        try:
            task_id = self.test_ids.get('task_id')
            run_id = self.test_ids.get('run_id')
            
            if not task_id or not run_id:
                logger.warning("âš ï¸ performance_metrics: Pas de task_id ou run_id, crÃ©ation...")
                if not task_id:
                    await self.test_tasks_table()
                    task_id = self.test_ids.get('task_id')
                if not run_id:
                    await self.test_task_runs_table()
                    run_id = self.test_ids.get('run_id')
            
            await db_persistence.record_performance_metrics(
                task_id=task_id,
                task_run_id=run_id,
                total_duration_seconds=300,
                ai_processing_time_seconds=150,
                testing_time_seconds=50,
                total_ai_calls=5,
                total_tokens_used=2000,
                total_ai_cost=0.05,
                test_coverage_final=85.5,
                retry_attempts=0
            )
            
            # VÃ©rifier l'insertion
            async with self.db_pool.acquire() as conn:
                count = await conn.fetchval("""
                    SELECT COUNT(*) FROM performance_metrics 
                    WHERE task_id = $1 AND task_run_id = $2
                """, task_id, run_id)
            
            if count > 0:
                logger.info(f"âœ… performance_metrics: MÃ©triques enregistrÃ©es ({count} entrÃ©e(s))")
                self.test_results['performance_metrics'] = True
                return True
            else:
                logger.error("âŒ performance_metrics: Aucune mÃ©trique trouvÃ©e")
                self.test_results['performance_metrics'] = False
                return False
                
        except Exception as e:
            logger.error(f"âŒ performance_metrics: Exception - {e}")
            self.test_results['performance_metrics'] = False
            return False
    
    async def test_human_validations_table(self) -> bool:
        """Teste l'insertion dans la table human_validations."""
        logger.info("ğŸ“‹ Test: table human_validations")
        try:
            task_id = self.test_ids.get('task_id')
            run_id = self.test_ids.get('run_id')
            step_id = self.test_ids.get('step_id')
            
            if not task_id:
                await self.test_tasks_table()
                task_id = self.test_ids.get('task_id')
            
            validation_service = HumanValidationService()
            await validation_service.init_db_pool()
            
            # CrÃ©er une demande de validation
            validation_request = HumanValidationRequest(
                validation_id=f"test_val_{int(datetime.now().timestamp())}",
                workflow_id="test_workflow",
                task_id=str(task_id),
                task_title="Test Validation",
                generated_code={"test.py": "print('hello')"},
                code_summary="Simple test code",
                files_modified=["test.py"],
                original_request="Create a test file",
                implementation_notes="Test implementation",
                test_results={"passed": True},
                pr_info=None,
                expires_at=datetime.now() + timedelta(hours=24),
                requested_by="test_script"
            )
            
            success = await validation_service.create_validation_request(
                validation_request,
                task_id=task_id,
                task_run_id=run_id,
                run_step_id=step_id
            )
            
            if success:
                self.test_ids['validation_id'] = validation_request.validation_id
                logger.info(f"âœ… human_validations: Validation crÃ©Ã©e avec ID {validation_request.validation_id}")
                self.test_results['human_validations'] = True
                
                await validation_service.close_db_pool()
                return True
            else:
                logger.error("âŒ human_validations: Ã‰chec crÃ©ation validation")
                self.test_results['human_validations'] = False
                await validation_service.close_db_pool()
                return False
                
        except Exception as e:
            logger.error(f"âŒ human_validations: Exception - {e}")
            self.test_results['human_validations'] = False
            return False
    
    async def test_human_validation_responses_table(self) -> bool:
        """Teste l'insertion dans la table human_validation_responses."""
        logger.info("ğŸ“‹ Test: table human_validation_responses")
        try:
            validation_id = self.test_ids.get('validation_id')
            if not validation_id:
                logger.warning("âš ï¸ human_validation_responses: Pas de validation_id, crÃ©ation d'une validation")
                await self.test_human_validations_table()
                validation_id = self.test_ids.get('validation_id')
            
            validation_service = HumanValidationService()
            await validation_service.init_db_pool()
            
            # CrÃ©er une rÃ©ponse de validation
            response = HumanValidationResponse(
                validation_id=validation_id,
                status=HumanValidationStatus.APPROVED,
                comments="Test approval",
                suggested_changes=None,
                approval_notes="Looks good",
                validated_by="test_validator",
                validated_at=datetime.now(),
                should_merge=True,
                should_continue_workflow=True
            )
            
            success = await validation_service.submit_validation_response(
                validation_id,
                response
            )
            
            if success:
                logger.info(f"âœ… human_validation_responses: RÃ©ponse crÃ©Ã©e pour validation {validation_id}")
                self.test_results['human_validation_responses'] = True
                await validation_service.close_db_pool()
                return True
            else:
                logger.error("âŒ human_validation_responses: Ã‰chec crÃ©ation rÃ©ponse")
                self.test_results['human_validation_responses'] = False
                await validation_service.close_db_pool()
                return False
                
        except Exception as e:
            logger.error(f"âŒ human_validation_responses: Exception - {e}")
            self.test_results['human_validation_responses'] = False
            return False
    
    async def test_validation_actions_table(self) -> bool:
        """Teste l'insertion dans la table validation_actions."""
        logger.info("ğŸ“‹ Test: table validation_actions")
        try:
            validation_id = self.test_ids.get('validation_id')
            if not validation_id:
                logger.warning("âš ï¸ validation_actions: Pas de validation_id, crÃ©ation d'une validation")
                await self.test_human_validations_table()
                validation_id = self.test_ids.get('validation_id')
            
            validation_service = HumanValidationService()
            await validation_service.init_db_pool()
            
            # CrÃ©er une action
            action_id = await validation_service.create_validation_action(
                validation_id=validation_id,
                action_type="merge_pr",
                action_data={"pr_number": 123, "branch": "test-branch"}
            )
            
            if action_id:
                # Mettre Ã  jour l'action
                update_success = await validation_service.update_validation_action(
                    action_id=action_id,
                    status="completed",
                    result_data={"merge_success": True},
                    merge_commit_hash="abc123",
                    merge_commit_url="https://github.com/test/repo/commit/abc123"
                )
                
                if update_success:
                    logger.info(f"âœ… validation_actions: Action crÃ©Ã©e et mise Ã  jour avec ID {action_id}")
                    self.test_results['validation_actions'] = True
                    await validation_service.close_db_pool()
                    return True
                else:
                    logger.error("âŒ validation_actions: Ã‰chec mise Ã  jour action")
                    self.test_results['validation_actions'] = False
                    await validation_service.close_db_pool()
                    return False
            else:
                logger.error("âŒ validation_actions: Ã‰chec crÃ©ation action")
                self.test_results['validation_actions'] = False
                await validation_service.close_db_pool()
                return False
                
        except Exception as e:
            logger.error(f"âŒ validation_actions: Exception - {e}")
            self.test_results['validation_actions'] = False
            return False
    
    async def test_system_config_table(self) -> bool:
        """Teste l'insertion dans la table system_config."""
        logger.info("ğŸ“‹ Test: table system_config")
        try:
            await system_config_service.init_db_pool()
            
            # Test crÃ©ation de configuration
            success_create = await system_config_service.create_or_update_config(
                key="test.config.key",
                value={"test": "value", "number": 42},
                description="Test configuration",
                config_type="application",
                updated_by="test_script"
            )
            
            if not success_create:
                logger.error("âŒ system_config: Ã‰chec crÃ©ation config")
                self.test_results['system_config'] = False
                await system_config_service.close_db_pool()
                return False
            
            # Test rÃ©cupÃ©ration
            config = await system_config_service.get_config("test.config.key")
            if not config:
                logger.error("âŒ system_config: Config crÃ©Ã©e mais non rÃ©cupÃ©rable")
                self.test_results['system_config'] = False
                await system_config_service.close_db_pool()
                return False
            
            # Test mise Ã  jour
            success_update = await system_config_service.create_or_update_config(
                key="test.config.key",
                value={"test": "updated_value", "number": 100},
                description="Updated test configuration",
                config_type="application",
                updated_by="test_script"
            )
            
            if success_update:
                logger.info(f"âœ… system_config: Configuration crÃ©Ã©e et mise Ã  jour")
                self.test_results['system_config'] = True
                await system_config_service.close_db_pool()
                return True
            else:
                logger.error("âŒ system_config: Ã‰chec mise Ã  jour config")
                self.test_results['system_config'] = False
                await system_config_service.close_db_pool()
                return False
                
        except Exception as e:
            logger.error(f"âŒ system_config: Exception - {e}")
            self.test_results['system_config'] = False
            return False
    
    async def run_all_tests(self):
        """ExÃ©cute tous les tests dans l'ordre."""
        logger.info("=" * 80)
        logger.info("ğŸš€ DÃ‰BUT DES TESTS D'INSERTION DANS LA BASE DE DONNÃ‰ES")
        logger.info("=" * 80)
        
        await self.initialize()
        
        # ExÃ©cuter les tests dans l'ordre des dÃ©pendances
        test_order = [
            ("tasks", self.test_tasks_table),
            ("task_runs", self.test_task_runs_table),
            ("run_steps", self.test_run_steps_table),
            ("ai_interactions", self.test_ai_interactions_table),
            ("ai_code_generations", self.test_ai_code_generations_table),
            ("test_results", self.test_test_results_table),
            ("pull_requests", self.test_pull_requests_table),
            ("performance_metrics", self.test_performance_metrics_table),
            ("human_validations", self.test_human_validations_table),
            ("human_validation_responses", self.test_human_validation_responses_table),
            ("validation_actions", self.test_validation_actions_table),
            ("system_config", self.test_system_config_table),
        ]
        
        for table_name, test_func in test_order:
            logger.info(f"\n{'=' * 80}")
            await test_func()
            await asyncio.sleep(0.5)  # Petit dÃ©lai entre les tests
        
        # Afficher le rÃ©sumÃ©
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š RÃ‰SUMÃ‰ DES TESTS")
        logger.info("=" * 80)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results.values() if result)
        failed_tests = total_tests - passed_tests
        
        for table, result in self.test_results.items():
            status = "âœ… PASS" if result else "âŒ FAIL"
            logger.info(f"{status} - {table}")
        
        logger.info("=" * 80)
        logger.info(f"Total: {total_tests} | RÃ©ussis: {passed_tests} | Ã‰chouÃ©s: {failed_tests}")
        
        success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0
        logger.info(f"Taux de rÃ©ussite: {success_rate:.1f}%")
        logger.info("=" * 80)
        
        await self.cleanup()
        
        return passed_tests == total_tests


async def main():
    """Point d'entrÃ©e principal."""
    tester = DatabaseInsertionTester()
    
    try:
        all_passed = await tester.run_all_tests()
        
        if all_passed:
            logger.info("\nğŸ‰ TOUS LES TESTS ONT RÃ‰USSI!")
            return 0
        else:
            logger.error("\nâŒ CERTAINS TESTS ONT Ã‰CHOUÃ‰")
            return 1
            
    except Exception as e:
        logger.error(f"\nğŸ’¥ ERREUR CRITIQUE: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
