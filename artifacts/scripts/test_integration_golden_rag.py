#!/usr/bin/env python3
"""Test d'intÃ©gration rapide du systÃ¨me Golden Dataset + RAG Multilingue."""

import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from services.evaluation.golden_dataset_manager import GoldenDatasetManager
from services.evaluation.golden_dataset_rag_extension import golden_dataset_rag_extension
from services.evaluation.llm_judge_rag_enriched import LLMJudgeRAGEnriched


async def test_integration():
    """Test d'intÃ©gration complet."""
    print("\n" + "="*80)
    print("ğŸ§ª TEST D'INTÃ‰GRATION: Golden Dataset + RAG Multilingue")
    print("="*80)
    
    try:
        # 1. Charger le golden dataset
        print("\n1ï¸âƒ£  Chargement du Golden Dataset...")
        manager = GoldenDatasetManager()
        df = manager.load_golden_sets()
        print(f"   âœ… {len(df)} tests chargÃ©s")
        
        # 2. Initialiser le vector store
        print("\n2ï¸âƒ£  Initialisation du Vector Store...")
        await golden_dataset_rag_extension.initialize()
        print(f"   âœ… Vector store initialisÃ©")
        
        # 3. VÃ©rifier si dÃ©jÃ  indexÃ©
        print("\n3ï¸âƒ£  VÃ©rification de l'indexation...")
        stats = await golden_dataset_rag_extension.get_golden_dataset_statistics()
        indexed_count = stats['vector_store']['total_indexed_contexts']
        
        if indexed_count > 0:
            print(f"   âœ… {indexed_count} examples dÃ©jÃ  indexÃ©s")
        else:
            print(f"   âš ï¸  Aucun example indexÃ©")
            print(f"   ğŸ’¡ ExÃ©cutez: python scripts/index_golden_dataset_with_rag.py")
            return False
        
        # 4. Test de recherche sÃ©mantique
        print("\n4ï¸âƒ£  Test de recherche sÃ©mantique...")
        test_query = "Comment fonctionne le systÃ¨me?"
        similar = await golden_dataset_rag_extension.find_similar_golden_examples(
            query=test_query,
            top_k=2
        )
        print(f"   Query: '{test_query}'")
        print(f"   âœ… {len(similar)} examples similaires trouvÃ©s")
        
        if similar:
            for i, ex in enumerate(similar[:2], 1):
                print(f"      {i}. SimilaritÃ©: {ex['similarity_score']:.2f} | Langue: {ex['language']}")
        
        # 5. Test du LLM Judge enrichi RAG
        print("\n5ï¸âƒ£  Test du LLM Judge enrichi RAG...")
        judge = LLMJudgeRAGEnriched(use_rag=True, rag_top_k=2)
        
        test = manager.get_test_by_index(0)
        result = await judge.evaluate_response_with_rag(
            reference_input=test['input_reference'],
            reference_output=test['output_reference'],
            agent_response=test['output_reference'],  # Simulation
            use_rag=True
        )
        
        print(f"   âœ… Ã‰valuation terminÃ©e")
        print(f"      â€¢ Score: {result['score']}/100")
        print(f"      â€¢ RAG activÃ©: {result['rag_enabled']}")
        print(f"      â€¢ Examples trouvÃ©s: {result['rag_similar_count']}")
        print(f"      â€¢ Langue: {result['rag_language_detected']}")
        
        # 6. RÃ©sumÃ©
        print("\n" + "="*80)
        print("âœ… TOUS LES TESTS D'INTÃ‰GRATION RÃ‰USSIS !")
        print("="*80)
        print("\nğŸ“‹ SystÃ¨me opÃ©rationnel:")
        print("   âœ… Golden Dataset Manager")
        print("   âœ… Extension RAG Multilingue")
        print("   âœ… Vector Store (pgvector)")
        print("   âœ… Recherche SÃ©mantique")
        print("   âœ… LLM Judge enrichi RAG")
        print("\nğŸš€ Le systÃ¨me est prÃªt pour l'Ã©valuation multilingue enrichie !")
        print()
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(test_integration())
    sys.exit(0 if success else 1)

