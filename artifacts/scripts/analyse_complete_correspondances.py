"""
Analyse compl√®te des correspondances entre les logs r√©els et le Golden Set.
Compare chaque interaction pour d√©terminer si l'√©valuation est fauss√©e.
"""

import pandas as pd
from pathlib import Path

def main():
    print("\n" + "=" * 80)
    print("üîç ANALYSE D√âTAILL√âE: LOGS R√âELS vs GOLDEN SET")
    print("=" * 80)
    
    base_path = Path(__file__).parent.parent / "data/golden_datasets"
    logs_path = base_path / "agent_interactions_log.csv"
    golden_path = base_path / "golden_sets_detailed.csv"
    
    print("\nüìÇ Chargement des donn√©es...")
    df_logs = pd.read_csv(logs_path)
    df_golden = pd.read_csv(golden_path)
    
    df_real = df_logs.iloc[3:].copy()
    
    print(f"‚úÖ {len(df_real)} interactions r√©elles charg√©es")
    print(f"‚úÖ {len(df_golden)} exemples Golden Set charg√©s")
    
    print("\n" + "=" * 80)
    print("üìä ANALYSE INTERACTION PAR INTERACTION")
    print("=" * 80)
    
    correspondances = []
    
    for idx, log_row in df_real.iterrows():
        print(f"\nüîπ INTERACTION #{idx-2}")
        print(f"   üìù Input: {log_row['input_text'][:80]}...")
        print(f"   Type: {log_row['interaction_type']}")
        
        input_lower = str(log_row['input_text']).lower()
        
        is_feature_check = any(keyword in input_lower for keyword in [
            "est ce que", "existe dans le projet", "est pr√©sent", 
            "fonctionnalit√©", "impl√©ment√©", "disponible"
        ])
        
        is_project_analysis = "projet" in input_lower or "repository" in input_lower
        
        print(f"\n   üéØ Classification:")
        print(f"      ‚Ä¢ Question sur fonctionnalit√© externe: {is_feature_check}")
        print(f"      ‚Ä¢ Analyse de projet externe: {is_project_analysis}")
        
        found_matches = []
        
        for _, golden_row in df_golden.iterrows():
            golden_input = str(golden_row['input_text_original']).lower()
            
            if "structure" in input_lower and "structure" in golden_input:
                found_matches.append({
                    'id': golden_row['input'],
                    'input': golden_row['input_text_original'][:60],
                    'similarity': 40,
                    'reason': "Pattern 'structure' commun"
                })
            
            if is_feature_check and ("comment" in golden_input or "quels sont" in golden_input):
                found_matches.append({
                    'id': golden_row['input'],
                    'input': golden_row['input_text_original'][:60],
                    'similarity': 30,
                    'reason': "Questions documentaires"
                })
        
        found_matches = sorted(found_matches, key=lambda x: x['similarity'], reverse=True)[:3]
        
        if found_matches:
            print(f"\n   ‚úÖ Correspondances trouv√©es: {len(found_matches)}")
            for match in found_matches:
                print(f"      ‚Ä¢ {match['id']}: {match['input']}...")
                print(f"        Similarit√©: {match['similarity']}% - {match['reason']}")
            correspondances.append({
                'interaction': idx-2,
                'has_match': True,
                'best_similarity': found_matches[0]['similarity']
            })
        else:
            print(f"\n   ‚ùå AUCUNE correspondance trouv√©e dans le Golden Set")
            print(f"      Raison: Pattern de question non couvert")
            correspondances.append({
                'interaction': idx-2,
                'has_match': False,
                'best_similarity': 0
            })
    
    print("\n" + "=" * 80)
    print("üìà STATISTIQUES GLOBALES")
    print("=" * 80)
    
    total = len(correspondances)
    with_match = sum(1 for c in correspondances if c['has_match'])
    without_match = total - with_match
    avg_similarity = sum(c['best_similarity'] for c in correspondances) / total if total > 0 else 0
    
    print(f"\nüìä R√©sum√©:")
    print(f"   ‚Ä¢ Total interactions: {total}")
    print(f"   ‚Ä¢ Avec correspondance: {with_match} ({with_match/total*100:.1f}%)")
    print(f"   ‚Ä¢ Sans correspondance: {without_match} ({without_match/total*100:.1f}%)")
    print(f"   ‚Ä¢ Similarit√© moyenne: {avg_similarity:.1f}%")
    
    print("\n" + "=" * 80)
    print("üéØ VERDICT FINAL")
    print("=" * 80)
    
    if without_match >= total * 0.6:  
        print("\n‚ùå √âVALUATION FAUSS√âE")
        print(f"   Raison: {without_match}/{total} interactions ({without_match/total*100:.0f}%)")
        print("   n'ont AUCUNE correspondance dans le Golden Set")
        print("\n   Le score de 75/100 est NON REPR√âSENTATIF car:")
        print("   ‚Ä¢ Les questions portent sur l'analyse de projets externes")
        print("   ‚Ä¢ Le Golden Set couvre l'architecture interne de l'agent")
        print("   ‚Ä¢ Il n'y a pas de r√©f√©rence pour √©valuer ces r√©ponses")
        verdict = "FAUSS√âE"
    elif without_match >= total * 0.4: 
        print("\n‚ö†Ô∏è  √âVALUATION PARTIELLEMENT FAUSS√âE")
        print(f"   Raison: {without_match}/{total} interactions ({without_match/total*100:.0f}%)")
        print("   n'ont pas de correspondance directe")
        print("\n   Le score de 75/100 est PARTIELLEMENT VALIDE:")
        print("   ‚Ä¢ Certaines questions correspondent au Golden Set")
        print("   ‚Ä¢ D'autres sont hors scope du Golden Set")
        print("   ‚Ä¢ Le score refl√®te un m√©lange de qualit√© et d'inad√©quation")
        verdict = "PARTIELLEMENT FAUSS√âE"
    else:  
        print("\n‚úÖ √âVALUATION VALIDE")
        print(f"   Raison: {with_match}/{total} interactions ({with_match/total*100:.0f}%)")
        print("   ont une correspondance dans le Golden Set")
        print("\n   Le score de 75/100 est REPR√âSENTATIF car:")
        print("   ‚Ä¢ La majorit√© des questions correspondent au Golden Set")
        print("   ‚Ä¢ Les patterns sont compatibles")
        print("   ‚Ä¢ L'√©valuation compare des √©l√©ments similaires")
        verdict = "VALIDE"
    
    print("\n" + "=" * 80)
    print(f"üèÅ R√âSULTAT: {verdict}")
    print("=" * 80)
    
    print("\nüí° RECOMMANDATIONS:")
    
    if verdict == "FAUSS√âE":
        print("\n   1. ‚ùå NE PAS utiliser ce score pour √©valuer l'agent")
        print("   2. ‚úÖ Cr√©er un nouveau Golden Set adapt√© aux questions d'analyse")
        print("   3. ‚úÖ S√©parer en 2 Golden Sets:")
        print("      ‚Ä¢ Golden Set A: Architecture agent (existant)")
        print("      ‚Ä¢ Golden Set B: Analyse projets (√† cr√©er)")
        print("   4. ‚úÖ Utiliser les 5 logs r√©els comme base pour Golden Set B")
    elif verdict == "PARTIELLEMENT FAUSS√âE":
        print("\n   1. ‚ö†Ô∏è  Utiliser ce score avec prudence")
        print("   2. ‚úÖ Enrichir le Golden Set avec des questions d'analyse")
        print("   3. ‚úÖ Documenter les limitations du score actuel")
        print("   4. ‚úÖ Ajouter au moins 20 exemples de questions similaires")
    else:
        print("\n   1. ‚úÖ Le score de 75/100 est fiable")
        print("   2. ‚úÖ Continuer √† utiliser ce Golden Set")
        print("   3. ‚úÖ Monitorer les nouvelles interactions")
        print("   4. ‚úÖ Mettre √† jour le Golden Set r√©guli√®rement")
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    main()

