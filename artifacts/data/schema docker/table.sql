CREATE TABLE public.ai_code_generations (
    ai_code_generations_id bigint NOT NULL,
    task_run_id bigint NOT NULL,
    provider character varying(50) NOT NULL,
    model character varying(100) NOT NULL,
    generation_type character varying(50),
    prompt text NOT NULL,
    generated_code text,
    tokens_used integer,
    response_time_ms integer,
    cost_estimate numeric(12,6),
    compilation_successful boolean,
    syntax_valid boolean,
    files_modified jsonb,
    generated_at timestamp with time zone DEFAULT now() NOT NULL
);
COMMENT ON TABLE public.ai_code_generations IS 'Historique des générations de code par IA';
ALTER TABLE public.ai_code_generations ALTER COLUMN ai_code_generations_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.ai_code_generations_ai_code_generations_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.ai_usage_logs (
    id integer NOT NULL,
    workflow_id character varying(255) NOT NULL,
    task_id character varying(255) NOT NULL,
    provider character varying(50) NOT NULL,
    model character varying(100) NOT NULL,
    operation character varying(100) NOT NULL,
    input_tokens integer DEFAULT 0 NOT NULL,
    output_tokens integer DEFAULT 0 NOT NULL,
    total_tokens integer DEFAULT 0 NOT NULL,
    estimated_cost numeric(10,6) DEFAULT 0.0 NOT NULL,
    "timestamp" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    duration_seconds numeric(8,3),
    success boolean DEFAULT true NOT NULL,
    error_message text,
    CONSTRAINT ai_usage_logs_cost_positive CHECK ((estimated_cost >= (0)::numeric)),
    CONSTRAINT ai_usage_logs_tokens_coherent CHECK ((total_tokens = (input_tokens + output_tokens))),
    CONSTRAINT ai_usage_logs_tokens_positive CHECK (((input_tokens >= 0) AND (output_tokens >= 0) AND (total_tokens >= 0)))
);
COMMENT ON TABLE public.ai_usage_logs IS 'Logs des usages IA avec tracking des tokens et coûts';
COMMENT ON COLUMN public.ai_usage_logs.workflow_id IS 'ID du workflow parent';
COMMENT ON COLUMN public.ai_usage_logs.task_id IS 'ID de la tâche Monday.com';
COMMENT ON COLUMN public.ai_usage_logs.provider IS 'Provider IA utilisé (claude, openai, etc.)';
COMMENT ON COLUMN public.ai_usage_logs.model IS 'Modèle spécifique utilisé';
COMMENT ON COLUMN public.ai_usage_logs.operation IS 'Type d''opération (analyze, implement, debug, etc.)';
COMMENT ON COLUMN public.ai_usage_logs.input_tokens IS 'Nombre de tokens en input (prompt)';
COMMENT ON COLUMN public.ai_usage_logs.output_tokens IS 'Nombre de tokens en output (réponse)';
COMMENT ON COLUMN public.ai_usage_logs.total_tokens IS 'Total des tokens (input + output)';
COMMENT ON COLUMN public.ai_usage_logs.estimated_cost IS 'Coût estimé en USD';  
COMMENT ON COLUMN public.ai_usage_logs.duration_seconds IS 'Durée de l''appel IA en secondes';  
COMMENT ON CONSTRAINT ai_usage_logs_cost_positive ON public.ai_usage_logs IS 'Les coûts ne peuvent pas être négatifs';
COMMENT ON CONSTRAINT ai_usage_logs_tokens_coherent ON public.ai_usage_logs IS 'total_tokens doit égaler input_tokens + output_tokens';
COMMENT ON CONSTRAINT ai_usage_logs_tokens_positive ON public.ai_usage_logs IS 'Les tokens ne peuvent pas être négatifs';
CREATE VIEW public.ai_cost_by_workflow AS
 SELECT ai_usage_logs.workflow_id,
    ai_usage_logs.task_id,
    count(*) AS total_ai_calls,
    sum(ai_usage_logs.input_tokens) AS total_input_tokens,
    sum(ai_usage_logs.output_tokens) AS total_output_tokens,
    sum(ai_usage_logs.total_tokens) AS total_tokens,
    sum(ai_usage_logs.estimated_cost) AS total_workflow_cost,
    min(ai_usage_logs."timestamp") AS started_at,
    max(ai_usage_logs."timestamp") AS last_ai_call,
    EXTRACT(epoch FROM (max(ai_usage_logs."timestamp") - min(ai_usage_logs."timestamp"))) AS duration_seconds,
    string_agg(DISTINCT (ai_usage_logs.provider)::text, ', '::text) AS providers_used,
    string_agg(DISTINCT (ai_usage_logs.operation)::text, ', '::text) AS operations_performed
   FROM public.ai_usage_logs
  WHERE (ai_usage_logs.success = true)
  GROUP BY ai_usage_logs.workflow_id, ai_usage_logs.task_id
  ORDER BY (sum(ai_usage_logs.estimated_cost)) DESC;
COMMENT ON VIEW public.ai_cost_by_workflow IS 'Coûts agrégés par workflow avec métriques de performance';
CREATE VIEW public.ai_cost_daily_summary AS
 SELECT date(ai_usage_logs."timestamp") AS usage_date,
    ai_usage_logs.provider,
    count(*) AS total_calls,
    sum(ai_usage_logs.input_tokens) AS total_input_tokens,
    sum(ai_usage_logs.output_tokens) AS total_output_tokens,
    sum(ai_usage_logs.total_tokens) AS total_tokens,
    sum(ai_usage_logs.estimated_cost) AS total_cost,
    avg(ai_usage_logs.estimated_cost) AS avg_cost_per_call,
    count(DISTINCT ai_usage_logs.workflow_id) AS unique_workflows,
    count(DISTINCT ai_usage_logs.task_id) AS unique_tasks
   FROM public.ai_usage_logs
  WHERE (ai_usage_logs.success = true)
  GROUP BY (date(ai_usage_logs."timestamp")), ai_usage_logs.provider
  ORDER BY (date(ai_usage_logs."timestamp")) DESC, (sum(ai_usage_logs.estimated_cost)) DESC;
COMMENT ON VIEW public.ai_cost_daily_summary IS 'Résumé quotidien des coûts IA par provider';
CREATE TABLE public.ai_cost_tracking (
    ai_cost_tracking_id bigint NOT NULL,
    task_id bigint,
    task_run_id bigint,
    provider character varying(50) NOT NULL,
    model character varying(100) NOT NULL,
    operation_type character varying(50),
    prompt_tokens integer NOT NULL,
    completion_tokens integer NOT NULL,
    total_tokens integer NOT NULL,
    cost_usd numeric(12,6) NOT NULL,
    created_at timestamp with time zone DEFAULT now() NOT NULL
);  
COMMENT ON TABLE public.ai_cost_tracking IS 'Tracking des coûts d''utilisation des API IA';
ALTER TABLE public.ai_cost_tracking ALTER COLUMN ai_cost_tracking_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.ai_cost_tracking_ai_cost_tracking_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.ai_interactions (
    ai_interactions_id bigint NOT NULL,
    run_step_id bigint NOT NULL,
    ai_provider character varying(50) NOT NULL,
    model_name character varying(100) NOT NULL,
    prompt text NOT NULL,
    response text,
    token_usage jsonb,
    latency_ms integer,
    created_at timestamp with time zone DEFAULT now() NOT NULL
);
COMMENT ON TABLE public.ai_interactions IS 'Historique des interactions avec les modèles IA';
ALTER TABLE public.ai_interactions ALTER COLUMN ai_interactions_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.ai_interactions_ai_interactions_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.ai_prompt_templates (
    template_id integer NOT NULL,
    template_name character varying(255) NOT NULL,
    template_category character varying(100),
    prompt_text text NOT NULL,
    model_recommended character varying(100),
    temperature numeric(3,2),
    max_tokens integer,
    description text,
    created_at timestamp with time zone DEFAULT now(),
    updated_at timestamp with time zone DEFAULT now(),
    created_by integer,
    is_active boolean DEFAULT true,
    avg_cost_usd numeric(10,6),
    usage_count integer DEFAULT 0,
    CONSTRAINT ai_prompt_templates_max_tokens_check CHECK ((max_tokens > 0))
);
CREATE SEQUENCE public.ai_prompt_templates_template_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.ai_prompt_templates_template_id_seq OWNED BY public.ai_prompt_templates.template_id;
CREATE TABLE public.ai_prompt_usage (
    usage_id bigint NOT NULL,
    template_id integer,
    task_id bigint,
    task_run_id bigint,
    executed_at timestamp with time zone DEFAULT now(),
    model_used character varying(100),
    temperature_used numeric(3,2),
    max_tokens_used integer,
    input_tokens integer,
    output_tokens integer,
    total_tokens integer GENERATED ALWAYS AS ((COALESCE(input_tokens, 0) + COALESCE(output_tokens, 0))) STORED,
    cost_usd numeric(10,6),
    execution_time_ms integer,
    success boolean DEFAULT true,
    error_message text
);
CREATE SEQUENCE public.ai_prompt_usage_usage_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.ai_prompt_usage_usage_id_seq OWNED BY public.ai_prompt_usage.usage_id;
CREATE TABLE public.ai_usage_logs_backup (
    id integer,
    workflow_id character varying(255),
    task_id character varying(255),
    provider character varying(50),
    model character varying(100),
    operation character varying(100),
    input_tokens integer,
    output_tokens integer,
    total_tokens integer,
    estimated_cost numeric(10,6),
    "timestamp" timestamp with time zone,
    duration_seconds numeric(8,3),
    success boolean,
    error_message text
);
CREATE SEQUENCE public.ai_usage_logs_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.ai_usage_logs_id_seq OWNED BY public.ai_usage_logs.id;
CREATE TABLE public.application_logs (
    application_logs_id bigint NOT NULL,
    task_id bigint,
    task_run_id bigint,
    run_step_id bigint,
    level character varying(20) NOT NULL,
    source_component character varying(100),
    action character varying(100),
    message text NOT NULL,
    metadata jsonb,
    user_id bigint,
    ip_address inet,
    ts timestamp with time zone DEFAULT now() NOT NULL,
    CONSTRAINT application_logs_level_chk CHECK (((level)::text = ANY ((ARRAY['DEBUG'::character varying, 'INFO'::character varying, 'WARNING'::character varying, 'ERROR'::character varying, 'CRITICAL'::character varying])::text[])))
);
COMMENT ON TABLE public.application_logs IS 'Logs structurés de l''application pour audit et debug';
ALTER TABLE public.application_logs ALTER COLUMN application_logs_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.application_logs_application_logs_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.audit_logs (
    id integer NOT NULL,
    "timestamp" timestamp without time zone DEFAULT CURRENT_TIMESTAMP,
    action character varying(100) NOT NULL,
    user_id integer,
    user_email character varying(255) NOT NULL,
    user_role character varying(50) NOT NULL,
    resource_type character varying(100),
    resource_id character varying(255),
    details jsonb DEFAULT '{}'::jsonb,
    ip_address character varying(45),
    user_agent text,
    status character varying(20) DEFAULT 'success'::character varying,
    severity character varying(20) DEFAULT 'low'::character varying,
    CONSTRAINT audit_logs_severity_check CHECK (((severity)::text = ANY ((ARRAY['low'::character varying, 'medium'::character varying, 'high'::character varying, 'critical'::character varying])::text[]))),
    CONSTRAINT audit_logs_status_check CHECK (((status)::text = ANY ((ARRAY['success'::character varying, 'failed'::character varying, 'warning'::character varying])::text[])))
);
COMMENT ON TABLE public.audit_logs IS 'Table des logs d''audit pour traçabilité complète (qui/quoi/quand)';
COMMENT ON COLUMN public.audit_logs.action IS 'Type d''action effectuée (ex: user_login, secret_viewed, config_updated)';
COMMENT ON COLUMN public.audit_logs.details IS 'Détails supplémentaires au format JSON';
COMMENT ON COLUMN public.audit_logs.status IS 'Résultat de l''action: success, failed, warning';
COMMENT ON COLUMN public.audit_logs.severity IS 'Niveau de gravité: low, medium, high, critical';
CREATE SEQUENCE public.audit_logs_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.audit_logs_id_seq OWNED BY public.audit_logs.id;
CREATE TABLE public.celery_taskmeta (
    id integer NOT NULL,
    task_id character varying(155),
    status character varying(50),
    result bytea,
    date_done timestamp without time zone,
    traceback text,
    name character varying(155),
    args bytea,
    kwargs bytea,
    worker character varying(155),
    retries integer,
    queue character varying(155)
);
CREATE TABLE public.celery_tasksetmeta (
    id integer NOT NULL,
    taskset_id character varying(155),
    result bytea,
    date_done timestamp without time zone
);
CREATE TABLE public.code_quality_feedback (
    feedback_id bigint NOT NULL,
    task_id bigint,
    task_run_id bigint,
    file_path character varying(500),
    line_number integer,
    category character varying(100),
    severity character varying(50),
    message text NOT NULL,
    suggestion text,
    source character varying(100),
    fixed boolean DEFAULT false,
    auto_fixable boolean DEFAULT false,
    code_snippet text,
    created_at timestamp with time zone DEFAULT now()
);
CREATE SEQUENCE public.code_quality_feedback_feedback_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.code_quality_feedback_feedback_id_seq OWNED BY public.code_quality_feedback.feedback_id;
CREATE TABLE public.human_validation_responses (
    human_validation_responses_id bigint NOT NULL,
    human_validation_id bigint NOT NULL,
    validation_id character varying(100) NOT NULL,
    response_status character varying(50) NOT NULL,
    comments text,
    suggested_changes text,
    approval_notes text,
    validated_by character varying(100),
    validated_at timestamp with time zone DEFAULT now() NOT NULL,
    should_merge boolean DEFAULT false NOT NULL,
    should_continue_workflow boolean DEFAULT true NOT NULL,
    validation_duration_seconds integer,
    user_agent text,
    ip_address inet,
    rejection_count integer DEFAULT 0 NOT NULL,
    modification_instructions text,
    should_retry_workflow boolean DEFAULT false NOT NULL,
    CONSTRAINT human_validation_responses_status_chk CHECK (((response_status)::text = ANY ((ARRAY['approved'::character varying, 'rejected'::character varying, 'abandoned'::character varying, 'expired'::character varying, 'cancelled'::character varying])::text[])))
);
COMMENT ON TABLE public.human_validation_responses IS 'Réponses des validateurs humains (approbation/rejet)';
ALTER TABLE public.human_validation_responses ALTER COLUMN human_validation_responses_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.human_validation_responses_human_validation_responses_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.human_validations (
    human_validations_id bigint NOT NULL,
    validation_id character varying(100) NOT NULL,
    task_id bigint NOT NULL,
    task_run_id bigint,
    run_step_id bigint,
    task_title character varying(500) NOT NULL,
    task_description text,
    original_request text NOT NULL,
    status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    generated_code jsonb NOT NULL,
    code_summary text NOT NULL,
    files_modified text[] NOT NULL,
    implementation_notes text,
    test_results jsonb,
    pr_info jsonb,
    workflow_id character varying(255),
    requested_by character varying(100) DEFAULT 'ai_agent'::character varying,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    updated_at timestamp with time zone DEFAULT now(),
    expires_at timestamp with time zone,
    rejection_count integer DEFAULT 0 NOT NULL,
    modification_instructions text,
    is_retry boolean DEFAULT false NOT NULL,
    parent_validation_id character varying(100),
    user_email character varying(100),
    CONSTRAINT human_validations_status_chk CHECK (((status)::text = ANY ((ARRAY['pending'::character varying, 'approved'::character varying, 'rejected'::character varying, 'abandoned'::character varying, 'expired'::character varying, 'cancelled'::character varying])::text[])))
);
COMMENT ON TABLE public.human_validations IS 'Demandes de validation humaine pour les codes générés par l''IA';
COMMENT ON COLUMN public.human_validations.validation_id IS 'ID unique généré par l''application pour tracking';
COMMENT ON COLUMN public.human_validations.task_id IS 'FK vers tasks.tasks_id (ID DB, PAS Monday item ID)';
COMMENT ON COLUMN public.human_validations.generated_code IS 'Code généré au format JSON {"filename": "content"}';
COMMENT ON COLUMN public.human_validations.files_modified IS 'Array PostgreSQL des fichiers modifiés';
COMMENT ON COLUMN public.human_validations.expires_at IS 'Date limite pour la validation (24h par défaut)';
COMMENT ON COLUMN public.human_validations.user_email IS 'Email de l''utilisateur pour notifications de timeout'
ALTER TABLE public.human_validations ALTER COLUMN human_validations_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.human_validations_human_validations_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.message_embeddings (
    id integer NOT NULL,
    monday_item_id character varying(50),
    monday_update_id character varying(100),
    task_id integer,
    message_text text NOT NULL,
    message_language character varying(10),
    cleaned_text text,
    embedding public.vector(1536) NOT NULL,
    message_type character varying(50) DEFAULT 'user_message'::character varying,
    intent_type character varying(50),
    user_id character varying(100),
    metadata jsonb DEFAULT '{}'::jsonb,
    created_at timestamp with time zone DEFAULT now(),
    updated_at timestamp with time zone DEFAULT now()
);
COMMENT ON TABLE public.message_embeddings IS 'Stockage des embeddings vectoriels des messages utilisateurs pour recherche sémantique multilingue';
COMMENT ON COLUMN public.message_embeddings.embedding IS 'Vecteur d''embedding 1536 dimensions (OpenAI text-embedding-3-small)';
CREATE SEQUENCE public.message_embeddings_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.message_embeddings_id_seq OWNED BY public.message_embeddings.id;
CREATE TABLE public.monday_updates_history (
    update_history_id bigint NOT NULL,
    monday_item_id bigint NOT NULL,
    update_id bigint,
    update_text text,
    update_author character varying(255),
    update_created_at timestamp with time zone,
    task_id bigint,
    triggered_reactivation boolean DEFAULT false,
    reactivation_id bigint,
    processed boolean DEFAULT false,
    created_at timestamp with time zone DEFAULT now()
);
CREATE SEQUENCE public.monday_updates_history_update_history_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.monday_updates_history_update_history_id_seq OWNED BY public.monday_updates_history.update_history_id;
CREATE TABLE public.performance_metrics (
    performance_metrics_id bigint NOT NULL,
    task_id bigint,
    task_run_id bigint,
    total_duration_seconds integer,
    queue_wait_time_seconds integer,
    ai_processing_time_seconds integer,
    testing_time_seconds integer,
    total_ai_calls integer DEFAULT 0,
    total_tokens_used integer DEFAULT 0,
    total_ai_cost numeric(12,6) DEFAULT 0.0,
    code_lines_generated integer DEFAULT 0,
    test_coverage_final numeric(5,2),
    security_issues_found integer DEFAULT 0,
    retry_attempts integer DEFAULT 0,
    success_rate numeric(5,2),
    recorded_at timestamp with time zone DEFAULT now() NOT NULL
);
COMMENT ON TABLE public.performance_metrics IS 'Métriques de performance agrégées par workflow';
ALTER TABLE public.performance_metrics ALTER COLUMN performance_metrics_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.performance_metrics_performance_metrics_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.project_context_embeddings (
    id integer NOT NULL,
    repository_url text NOT NULL,
    repository_name character varying(255),
    context_text text NOT NULL,
    context_type character varying(50) NOT NULL,
    file_path text,
    embedding public.vector(1536) NOT NULL,
    metadata jsonb DEFAULT '{}'::jsonb,
    language character varying(10),
    created_at timestamp with time zone DEFAULT now(),
    updated_at timestamp with time zone DEFAULT now()
);
COMMENT ON TABLE public.project_context_embeddings IS 'Stockage des embeddings du contexte de projet (README, code, docs) pour enrichir les réponses';
CREATE SEQUENCE public.project_context_embeddings_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.project_context_embeddings_id_seq OWNED BY public.project_context_embeddings.id;
CREATE TABLE public.pull_requests (
    pull_requests_id bigint NOT NULL,
    task_id bigint NOT NULL,
    task_run_id bigint,
    github_pr_number integer,
    github_pr_url character varying(500),
    pr_title character varying(500),
    pr_description text,
    pr_status character varying(50),
    mergeable boolean,
    conflicts boolean DEFAULT false,
    reviews_required integer DEFAULT 1,
    reviews_approved integer DEFAULT 0,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    merged_at timestamp with time zone,
    closed_at timestamp with time zone,
    head_sha character(40),
    base_branch character varying(100) DEFAULT 'main'::character varying,
    feature_branch character varying(100)
);
COMMENT ON TABLE public.pull_requests IS 'Pull Requests créées par l''agent IA';
ALTER TABLE public.pull_requests ALTER COLUMN pull_requests_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.pull_requests_pull_requests_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.rate_limits (
    rate_limit_id bigint NOT NULL,
    resource_identifier character varying(255) NOT NULL,
    user_id bigint,
    max_requests integer NOT NULL,
    limit_window character varying(50) NOT NULL,
    current_requests integer DEFAULT 0,
    window_start timestamp with time zone DEFAULT now(),
    created_at timestamp with time zone DEFAULT now(),
    last_request_at timestamp with time zone,
    exceeded_count integer DEFAULT 0
);
CREATE SEQUENCE public.rate_limits_rate_limit_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.rate_limits_rate_limit_id_seq OWNED BY public.rate_limits.rate_limit_id;
CREATE TABLE public.run_step_checkpoints (
    checkpoint_id bigint NOT NULL,
    step_id bigint NOT NULL,
    checkpoint_data jsonb,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    updated_at timestamp with time zone
);
COMMENT ON TABLE public.run_step_checkpoints IS 'Checkpoints pour la reprise après erreur';
ALTER TABLE public.run_step_checkpoints ALTER COLUMN checkpoint_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.run_step_checkpoints_checkpoint_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.run_steps (
    run_steps_id bigint NOT NULL,
    task_run_id bigint NOT NULL,
    node_name character varying(100) NOT NULL,
    step_order integer NOT NULL,
    status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    retry_count integer DEFAULT 0 NOT NULL,
    max_retries integer DEFAULT 3 NOT NULL,
    input_data jsonb,
    output_data jsonb,
    output_log text,
    error_details text,
    checkpoint_data jsonb,
    started_at timestamp with time zone,
    completed_at timestamp with time zone,
    checkpoint_saved_at timestamp with time zone,
    duration_seconds integer,
    CONSTRAINT run_steps_status_chk CHECK (((status)::text = ANY ((ARRAY['pending'::character varying, 'running'::character varying, 'completed'::character varying, 'failed'::character varying, 'skipped'::character varying, 'retry'::character varying])::text[])))
);
COMMENT ON TABLE public.run_steps IS 'Étapes individuelles d''un workflow (nœuds LangGraph)';
ALTER TABLE public.run_steps ALTER COLUMN run_steps_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.run_steps_run_steps_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.system_config (
    system_config_id bigint NOT NULL,
    key character varying(100) NOT NULL,
    value jsonb NOT NULL,
    description text,
    config_type character varying(50) DEFAULT 'application'::character varying NOT NULL,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    updated_at timestamp with time zone DEFAULT now() NOT NULL,
    updated_by character varying(100)
);
COMMENT ON TABLE public.system_config IS 'Configuration système versionnée';
ALTER TABLE public.system_config ALTER COLUMN system_config_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.system_config_system_config_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.system_users (
    user_id bigint NOT NULL,
    username character varying(100) NOT NULL,
    email character varying(255) NOT NULL,
    full_name character varying(200),
    role character varying(50) DEFAULT 'user'::character varying,
    is_active boolean DEFAULT true,
    created_at timestamp with time zone DEFAULT now(),
    last_login_at timestamp with time zone,
    preferences jsonb DEFAULT '{}'::jsonb,
    monday_user_id bigint,
    api_usage_limit integer DEFAULT 1000,
    monthly_reset_day integer DEFAULT 1,
    notification_preferences jsonb DEFAULT '{"email_on_failure": true, "email_on_completion": true}'::jsonb
);
CREATE SEQUENCE public.system_users_user_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.system_users_user_id_seq OWNED BY public.system_users.user_id;
CREATE TABLE public.task_context_memory (
    memory_id bigint NOT NULL,
    task_id bigint,
    context_key character varying(255) NOT NULL,
    context_value jsonb NOT NULL,
    relevance_score numeric(3,2) DEFAULT 1.0,
    created_at timestamp with time zone DEFAULT now(),
    accessed_at timestamp with time zone,
    access_count integer DEFAULT 0
);
CREATE SEQUENCE public.task_context_memory_memory_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.task_context_memory_memory_id_seq OWNED BY public.task_context_memory.memory_id;
CREATE SEQUENCE public.task_id_sequence
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
CREATE TABLE public.task_runs (
    tasks_runs_id bigint NOT NULL,
    task_id bigint,
    run_number integer,
    status character varying(50) DEFAULT 'started'::character varying NOT NULL,
    celery_task_id character varying(255),
    current_node character varying(100),
    progress_percentage integer DEFAULT 0,
    ai_provider character varying(50),
    model_name character varying(100),
    result jsonb,
    error_message text,
    git_branch_name character varying(255),
    pull_request_url character varying(500),
    started_at timestamp with time zone DEFAULT now() NOT NULL,
    completed_at timestamp with time zone,
    duration_seconds integer,
    last_merged_pr_url character varying(500),
    active_task_ids text[],
    last_task_id character varying(255),
    task_started_at timestamp with time zone,
    is_reactivation boolean DEFAULT false NOT NULL,
    parent_run_id bigint,
    reactivation_count integer DEFAULT 0 NOT NULL,
    browser_qa_results jsonb,
    CONSTRAINT task_runs_status_chk CHECK (((status)::text = ANY ((ARRAY['started'::character varying, 'running'::character varying, 'completed'::character varying, 'failed'::character varying, 'retry'::character varying])::text[])))
);
COMMENT ON TABLE public.task_runs IS 'Exécutions de workflows (jobs Celery)';
COMMENT ON COLUMN public.task_runs.celery_task_id IS 'ID de la tâche Celery (UUID)';
COMMENT ON COLUMN public.task_runs.last_merged_pr_url IS 'URL de la dernière PR fusionnée (pour résolution repository)';
COMMENT ON COLUMN public.task_runs.active_task_ids IS 'Liste des IDs de tâches Celery actives (array JSON)';
COMMENT ON COLUMN public.task_runs.last_task_id IS 'ID de la dernière tâche Celery lancée';
COMMENT ON COLUMN public.task_runs.task_started_at IS 'Date de démarrage de la dernière tâche Celery';
COMMENT ON COLUMN public.task_runs.is_reactivation IS 'Indique si ce run est une réactivation';
COMMENT ON COLUMN public.task_runs.parent_run_id IS 'ID du run parent pour les réactivations (permet de tracer la lignée des workflows)';
COMMENT ON COLUMN public.task_runs.browser_qa_results IS 'Résultats des tests Browser QA automatisés (Chrome DevTools MCP)';
ALTER TABLE public.task_runs ALTER COLUMN tasks_runs_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.task_runs_tasks_runs_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.task_update_triggers (
    trigger_id bigint NOT NULL,
    task_id bigint,
    monday_update_id bigint,
    update_content text,
    triggered_at timestamp with time zone DEFAULT now(),
    trigger_type character varying(50),
    action_taken character varying(100),
    new_run_id bigint,
    metadata jsonb
);
CREATE SEQUENCE public.task_update_triggers_trigger_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.task_update_triggers_trigger_id_seq OWNED BY public.task_update_triggers.trigger_id;
CREATE TABLE public.tasks (
    tasks_id bigint NOT NULL,
    monday_item_id bigint NOT NULL,
    monday_board_id bigint,
    title character varying(500) NOT NULL,
    description text,
    priority character varying(50),
    repository_url character varying(500) NOT NULL,
    repository_name character varying(200),
    default_branch character varying(100) DEFAULT 'main'::character varying,
    monday_status character varying(100),
    internal_status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    created_by_user_id bigint,
    assigned_to text,
    last_run_id bigint,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    updated_at timestamp with time zone DEFAULT now() NOT NULL,
    started_at timestamp with time zone,
    completed_at timestamp with time zone,
    is_locked boolean DEFAULT false,
    locked_at timestamp without time zone,
    locked_by character varying(255),
    cooldown_until timestamp without time zone,
    last_reactivation_attempt timestamp without time zone,
    failed_reactivation_attempts integer DEFAULT 0,
    reactivation_count integer DEFAULT 0,
    active_task_ids text[],
    reactivated_at timestamp without time zone,
    previous_status character varying(50),
    CONSTRAINT tasks_internal_status_chk CHECK (((internal_status)::text = ANY ((ARRAY['pending'::character varying, 'processing'::character varying, 'testing'::character varying, 'debugging'::character varying, 'quality_check'::character varying, 'completed'::character varying, 'failed'::character varying])::text[])))
);
COMMENT ON TABLE public.tasks IS 'Tâches provenant de Monday.com pour le workflow AI';
COMMENT ON COLUMN public.tasks.tasks_id IS 'ID interne de la base de données (utilisé pour les foreign keys)';
COMMENT ON COLUMN public.tasks.monday_item_id IS 'ID de l''item Monday.com (unique)';
COMMENT ON COLUMN public.tasks.is_locked IS 'Indique si la tâche est verrouillée pour éviter les modifications concurrentes';
COMMENT ON COLUMN public.tasks.locked_at IS 'Date du verrouillage';
COMMENT ON COLUMN public.tasks.locked_by IS 'Identifiant du processus/tâche qui a verrouillé (ex: celery_task_id)';
COMMENT ON COLUMN public.tasks.cooldown_until IS 'Date de fin du cooldown (pendant cette période, pas de réactivation)';
COMMENT ON COLUMN public.tasks.last_reactivation_attempt IS 'Date de la dernière tentative de réactivation';
COMMENT ON COLUMN public.tasks.failed_reactivation_attempts IS 'Nombre de tentatives de réactivation échouées consécutives';
COMMENT ON COLUMN public.tasks.reactivation_count IS 'Nombre de fois que la tâche a été réactivée';
COMMENT ON COLUMN public.tasks.reactivated_at IS 'Date de la dernière réactivation de la tâche';
COMMENT ON COLUMN public.tasks.previous_status IS 'Statut précédent avant réactivation';
ALTER TABLE public.tasks ALTER COLUMN tasks_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.tasks_tasks_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE SEQUENCE public.taskset_id_sequence
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
CREATE TABLE public.test_results (
    test_results_id bigint NOT NULL,
    task_run_id bigint NOT NULL,
    passed boolean NOT NULL,
    status character varying(50) DEFAULT 'passed'::character varying NOT NULL,
    tests_total integer DEFAULT 0,
    tests_passed integer DEFAULT 0,
    tests_failed integer DEFAULT 0,
    tests_skipped integer DEFAULT 0,
    coverage_percentage numeric(5,2),
    pytest_report jsonb,
    security_scan_report jsonb,
    executed_at timestamp with time zone DEFAULT now() NOT NULL,
    duration_seconds integer
);
COMMENT ON TABLE public.test_results IS 'Résultats des tests automatisés';
ALTER TABLE public.test_results ALTER COLUMN test_results_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.test_results_test_results_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.users (
    user_id integer NOT NULL,
    email character varying(255) NOT NULL,
    name character varying(255) NOT NULL,
    password_hash character varying(255) NOT NULL,
    role character varying(50) DEFAULT 'Viewer'::character varying NOT NULL,
    is_active boolean DEFAULT true,
    created_at timestamp without time zone DEFAULT CURRENT_TIMESTAMP,
    updated_at timestamp without time zone DEFAULT CURRENT_TIMESTAMP,
    last_login timestamp without time zone,
    CONSTRAINT users_role_check CHECK (((role)::text = ANY ((ARRAY['Admin'::character varying, 'Developer'::character varying, 'Viewer'::character varying, 'Auditor'::character varying])::text[])))
);
COMMENT ON TABLE public.users IS 'Table des utilisateurs autorisés à accéder à l''interface admin';
COMMENT ON COLUMN public.users.role IS 'Rôle de l''utilisateur: Admin, Developer, Viewer, ou Auditor';
COMMENT ON COLUMN public.users.is_active IS 'Indique si l''utilisateur peut se connecter';
COMMENT ON COLUMN public.users.last_login IS 'Date et heure de la dernière connexion réussie';
CREATE SEQUENCE public.users_user_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.users_user_id_seq OWNED BY public.users.user_id;
CREATE TABLE public.workflow_reactivations (
    id integer NOT NULL,
    workflow_id integer NOT NULL,
    reactivated_at timestamp with time zone DEFAULT now() NOT NULL,
    trigger_type character varying(50) NOT NULL,
    update_data jsonb,
    task_id character varying(255),
    status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    error_message text,
    completed_at timestamp with time zone,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    updated_at timestamp with time zone DEFAULT now() NOT NULL,
    CONSTRAINT workflow_reactivations_status_check CHECK (((status)::text = ANY ((ARRAY['pending'::character varying, 'processing'::character varying, 'completed'::character varying, 'failed'::character varying])::text[]))),
    CONSTRAINT workflow_reactivations_trigger_type_check CHECK (((trigger_type)::text = ANY ((ARRAY['update'::character varying, 'manual'::character varying, 'automatic'::character varying])::text[])))
);
COMMENT ON TABLE public.workflow_reactivations IS 'Table d''enregistrement des réactivations de workflow pour suivi et audit';
COMMENT ON COLUMN public.workflow_reactivations.id IS 'Identifiant unique de la réactivation';
COMMENT ON COLUMN public.workflow_reactivations.workflow_id IS 'ID du workflow/tâche réactivé (référence à tasks.tasks_id)';
COMMENT ON COLUMN public.workflow_reactivations.reactivated_at IS 'Date et heure de la réactivation';
COMMENT ON COLUMN public.workflow_reactivations.trigger_type IS 'Type de déclencheur de la réactivation (update, manual, automatic)';
COMMENT ON COLUMN public.workflow_reactivations.update_data IS 'Données de l''update Monday.com ou contexte de la réactivation (JSON)';
COMMENT ON COLUMN public.workflow_reactivations.task_id IS 'ID de la tâche Celery lancée pour cette réactivation';
COMMENT ON COLUMN public.workflow_reactivations.status IS 'Statut de la réactivation (pending, processing, completed, failed)';
COMMENT ON COLUMN public.workflow_reactivations.error_message IS 'Message d''erreur en cas d''échec de la réactivation';
COMMENT ON COLUMN public.workflow_reactivations.completed_at IS 'Date de complétion (succès ou échec) de la réactivation';
CREATE VIEW public.v_recent_reactivations AS
 SELECT wr.id,
    wr.workflow_id,
    t.title AS task_title,
    wr.trigger_type,
    wr.status,
    wr.reactivated_at,
    wr.completed_at,
    (EXTRACT(epoch FROM (COALESCE(wr.completed_at, now()) - wr.reactivated_at)))::integer AS duration_seconds,
    wr.error_message
   FROM (public.workflow_reactivations wr
     JOIN public.tasks t ON ((wr.workflow_id = t.tasks_id)))
  WHERE (wr.reactivated_at >= (now() - '24:00:00'::interval))
  ORDER BY wr.reactivated_at DESC;
COMMENT ON VIEW public.v_recent_reactivations IS 'Liste des réactivations des dernières 24 heures avec durées et statuts';
CREATE VIEW public.v_workflow_reactivation_stats AS
 SELECT wr.workflow_id,
    t.title AS task_title,
    t.internal_status AS current_status,
    count(*) AS total_reactivations,
    count(*) FILTER (WHERE ((wr.status)::text = 'completed'::text)) AS successful_reactivations,
    count(*) FILTER (WHERE ((wr.status)::text = 'failed'::text)) AS failed_reactivations,
    count(*) FILTER (WHERE ((wr.status)::text = ANY ((ARRAY['pending'::character varying, 'processing'::character varying])::text[]))) AS ongoing_reactivations,
    max(wr.reactivated_at) AS last_reactivation_at,
    avg(EXTRACT(epoch FROM (wr.completed_at - wr.reactivated_at))) FILTER (WHERE (wr.completed_at IS NOT NULL)) AS avg_duration_seconds
   FROM (public.workflow_reactivations wr
     JOIN public.tasks t ON ((wr.workflow_id = t.tasks_id)))
  GROUP BY wr.workflow_id, t.title, t.internal_status;
COMMENT ON VIEW public.v_workflow_reactivation_stats IS 'Statistiques de réactivation par workflow avec taux de succès et durées moyennes';
CREATE TABLE public.validation_actions (
    validation_actions_id bigint NOT NULL,
    human_validation_id bigint NOT NULL,
    validation_id character varying(100) NOT NULL,
    action_type character varying(50) NOT NULL,
    action_status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    action_data jsonb,
    result_data jsonb,
    merge_commit_hash character varying(100),
    merge_commit_url character varying(500),
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    started_at timestamp with time zone,
    completed_at timestamp with time zone,
    error_message text,
    retry_count integer DEFAULT 0 NOT NULL,
    CONSTRAINT validation_actions_status_chk CHECK (((action_status)::text = ANY ((ARRAY['pending'::character varying, 'in_progress'::character varying, 'completed'::character varying, 'failed'::character varying, 'cancelled'::character varying])::text[]))),
    CONSTRAINT validation_actions_type_chk CHECK (((action_type)::text = ANY ((ARRAY['merge_pr'::character varying, 'reject_pr'::character varying, 'update_monday'::character varying, 'cleanup_branch'::character varying, 'notify_user'::character varying])::text[])))
);
COMMENT ON TABLE public.validation_actions IS 'Actions effectuées suite à la validation (merge, etc.)';
ALTER TABLE public.validation_actions ALTER COLUMN validation_actions_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.validation_actions_validation_actions_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE VIEW public.validation_dashboard AS
 SELECT hv.human_validations_id,
    hv.validation_id,
    hv.task_title,
    hv.status,
    hv.created_at,
    hv.expires_at,
        CASE
            WHEN ((hv.expires_at IS NOT NULL) AND (hv.expires_at < (now() + '01:00:00'::interval))) THEN true
            ELSE false
        END AS is_urgent,
        CASE
            WHEN ((hv.test_results IS NOT NULL) AND (((hv.test_results ->> 'success'::text))::boolean = false)) THEN true
            ELSE false
        END AS has_test_failures,
    array_length(hv.files_modified, 1) AS files_count,
    (hv.pr_info ->> 'url'::text) AS pr_url,
    t.priority,
    t.repository_url,
    hvr.validated_by,
    hvr.validated_at,
    hvr.comments AS validation_comments
   FROM ((public.human_validations hv
     JOIN public.tasks t ON ((hv.task_id = t.tasks_id)))
     LEFT JOIN public.human_validation_responses hvr ON ((hv.human_validations_id = hvr.human_validation_id)))
  ORDER BY
        CASE
            WHEN ((hv.status)::text = 'pending'::text) THEN 0
            ELSE 1
        END,
        CASE
            WHEN ((hv.expires_at IS NOT NULL) AND (hv.expires_at < (now() + '01:00:00'::interval))) THEN 0
            ELSE 1
        END, hv.created_at DESC;
COMMENT ON VIEW public.validation_dashboard IS 'Vue optimisée pour l''interface d''administration des validations';
CREATE VIEW public.validation_history AS
 SELECT hv.validation_id,
    hv.task_title,
    hv.status,
    hv.created_at,
    hv.expires_at,
    hvr.response_status,
    hvr.validated_by,
    hvr.validated_at,
    hvr.validation_duration_seconds,
    va.action_type,
    va.action_status,
    va.merge_commit_hash,
    t.repository_url,
    t.priority
   FROM (((public.human_validations hv
     JOIN public.tasks t ON ((hv.task_id = t.tasks_id)))
     LEFT JOIN public.human_validation_responses hvr ON ((hv.human_validations_id = hvr.human_validation_id)))
     LEFT JOIN public.validation_actions va ON ((hv.human_validations_id = va.human_validation_id)))
  WHERE ((hv.status)::text <> 'pending'::text)
  ORDER BY hv.created_at DESC;
COMMENT ON VIEW public.validation_history IS 'Historique complet des validations avec actions associées';
CREATE TABLE public.webhook_events (
    webhook_events_id bigint NOT NULL,
    source character varying(50) NOT NULL,
    event_type character varying(100),
    payload jsonb NOT NULL,
    headers jsonb,
    signature text,
    processed boolean DEFAULT false NOT NULL,
    processing_status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    error_message text,
    related_task_id bigint,
    received_at timestamp with time zone DEFAULT now() NOT NULL,
    processed_at timestamp with time zone
)
PARTITION BY RANGE (received_at);
COMMENT ON TABLE public.webhook_events IS 'Événements webhook reçus (Monday.com, GitHub, etc.)';
CREATE TABLE public.webhook_events_2025_09 (
    webhook_events_id bigint NOT NULL,
    source character varying(50) NOT NULL,
    event_type character varying(100),
    payload jsonb NOT NULL,
    headers jsonb,
    signature text,
    processed boolean DEFAULT false NOT NULL,
    processing_status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    error_message text,
    related_task_id bigint,
    received_at timestamp with time zone DEFAULT now() NOT NULL,
    processed_at timestamp with time zone
);
CREATE TABLE public.webhook_events_p2025_10 (
    webhook_events_id bigint NOT NULL,
    source character varying(50) NOT NULL,
    event_type character varying(100),
    payload jsonb NOT NULL,
    headers jsonb,
    signature text,
    processed boolean DEFAULT false NOT NULL,
    processing_status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    error_message text,
    related_task_id bigint,
    received_at timestamp with time zone DEFAULT now() NOT NULL,
    processed_at timestamp with time zone
);
CREATE TABLE public.webhook_events_p2025_11 (
    webhook_events_id bigint NOT NULL,
    source character varying(50) NOT NULL,
    event_type character varying(100),
    payload jsonb NOT NULL,
    headers jsonb,
    signature text,
    processed boolean DEFAULT false NOT NULL,
    processing_status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    error_message text,
    related_task_id bigint,
    received_at timestamp with time zone DEFAULT now() NOT NULL,
    processed_at timestamp with time zone
);
CREATE TABLE public.webhook_events_p2025_12 (
    webhook_events_id bigint NOT NULL,
    source character varying(50) NOT NULL,
    event_type character varying(100),
    payload jsonb NOT NULL,
    headers jsonb,
    signature text,
    processed boolean DEFAULT false NOT NULL,
    processing_status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    error_message text,
    related_task_id bigint,
    received_at timestamp with time zone DEFAULT now() NOT NULL,
    processed_at timestamp with time zone
);
CREATE TABLE public.webhook_events_p2026_01 (
    webhook_events_id bigint NOT NULL,
    source character varying(50) NOT NULL,
    event_type character varying(100),
    payload jsonb NOT NULL,
    headers jsonb,
    signature text,
    processed boolean DEFAULT false NOT NULL,
    processing_status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    error_message text,
    related_task_id bigint,
    received_at timestamp with time zone DEFAULT now() NOT NULL,
    processed_at timestamp with time zone
);
ALTER TABLE public.webhook_events ALTER COLUMN webhook_events_id ADD GENERATED BY DEFAULT AS IDENTITY (
    SEQUENCE NAME public.webhook_events_webhook_events_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1
);
CREATE TABLE public.workflow_cooldowns (
    cooldown_id integer NOT NULL,
    task_id integer NOT NULL,
    cooldown_type character varying(50) NOT NULL,
    cooldown_until timestamp without time zone NOT NULL,
    failed_reactivation_attempts integer DEFAULT 0,
    metadata jsonb DEFAULT '{}'::jsonb,
    created_at timestamp without time zone DEFAULT now(),
    updated_at timestamp without time zone DEFAULT now()
);
CREATE SEQUENCE public.workflow_cooldowns_cooldown_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.workflow_cooldowns_cooldown_id_seq OWNED BY public.workflow_cooldowns.cooldown_id;
CREATE TABLE public.workflow_locks (
    lock_id integer NOT NULL,
    task_id integer NOT NULL,
    lock_key character varying(255) NOT NULL,
    is_locked boolean DEFAULT true,
    is_active boolean DEFAULT true,
    locked_at timestamp without time zone DEFAULT now(),
    released_at timestamp without time zone,
    lock_owner character varying(255),
    metadata jsonb DEFAULT '{}'::jsonb,
    created_at timestamp without time zone DEFAULT now(),
    updated_at timestamp without time zone DEFAULT now()
);
CREATE SEQUENCE public.workflow_locks_lock_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.workflow_locks_lock_id_seq OWNED BY public.workflow_locks.lock_id;
CREATE VIEW public.workflow_metrics_summary AS
 SELECT t.tasks_id,
    t.title,
    t.repository_url,
    t.internal_status,
    count(DISTINCT tr.tasks_runs_id) AS total_runs,
    count(DISTINCT tr.tasks_runs_id) FILTER (WHERE ((tr.status)::text = 'completed'::text)) AS successful_runs,
    count(DISTINCT tr.tasks_runs_id) FILTER (WHERE ((tr.status)::text = 'failed'::text)) AS failed_runs,
    avg(pm.total_duration_seconds) AS avg_duration_seconds,
    avg(pm.total_ai_cost) AS avg_cost_usd,
    max(tr.completed_at) AS last_run_at
   FROM ((public.tasks t
     LEFT JOIN public.task_runs tr ON ((t.tasks_id = tr.task_id)))
     LEFT JOIN public.performance_metrics pm ON ((tr.tasks_runs_id = pm.task_run_id)))
  GROUP BY t.tasks_id, t.title, t.repository_url, t.internal_status
  ORDER BY (max(tr.completed_at)) DESC NULLS LAST;
COMMENT ON VIEW public.workflow_metrics_summary IS 'Résumé des métriques par tâche';
CREATE TABLE public.workflow_queue (
    queue_id character varying(50) NOT NULL,
    monday_item_id bigint NOT NULL,
    task_id integer,
    status character varying(50) DEFAULT 'pending'::character varying NOT NULL,
    priority integer DEFAULT 5 NOT NULL,
    queued_at timestamp with time zone DEFAULT now() NOT NULL,
    started_at timestamp with time zone,
    completed_at timestamp with time zone,
    celery_task_id character varying(255),
    error text,
    retry_count integer DEFAULT 0 NOT NULL,
    payload jsonb NOT NULL,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    updated_at timestamp with time zone DEFAULT now() NOT NULL
);
COMMENT ON TABLE public.workflow_queue IS 'Queue de workflows pour éviter le traitement concurrent par Monday item';
COMMENT ON COLUMN public.workflow_queue.queue_id IS 'Identifiant unique de la queue entry';
COMMENT ON COLUMN public.workflow_queue.monday_item_id IS 'ID de l''item Monday.com';
COMMENT ON COLUMN public.workflow_queue.task_id IS 'ID de la tâche en base (si créée)';
COMMENT ON COLUMN public.workflow_queue.status IS 'Statut: pending, running, waiting_validation, completed, failed, cancelled, timeout';
COMMENT ON COLUMN public.workflow_queue.priority IS 'Priorité (1-10, plus haut = plus prioritaire)';
COMMENT ON COLUMN public.workflow_queue.celery_task_id IS 'ID de la tâche Celery associée';
COMMENT ON COLUMN public.workflow_queue.payload IS 'Payload complet du webhook pour rejouer si nécessaire';
CREATE SEQUENCE public.workflow_reactivations_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER SEQUENCE public.workflow_reactivations_id_seq OWNED BY public.workflow_reactivations.id;
ALTER TABLE ONLY public.webhook_events ATTACH PARTITION public.webhook_events_2025_09 FOR VALUES FROM ('2025-09-01 00:00:00+00') TO ('2025-10-01 00:00:00+00');
ALTER TABLE ONLY public.webhook_events ATTACH PARTITION public.webhook_events_p2025_10 FOR VALUES FROM ('2025-10-01 00:00:00+00') TO ('2025-11-01 00:00:00+00');
ALTER TABLE ONLY public.webhook_events ATTACH PARTITION public.webhook_events_p2025_11 FOR VALUES FROM ('2025-11-01 00:00:00+00') TO ('2025-12-01 00:00:00+00');
ALTER TABLE ONLY public.webhook_events ATTACH PARTITION public.webhook_events_p2025_12 FOR VALUES FROM ('2025-12-01 00:00:00+00') TO ('2026-01-01 00:00:00+00');
ALTER TABLE ONLY public.webhook_events ATTACH PARTITION public.webhook_events_p2026_01 FOR VALUES FROM ('2026-01-01 00:00:00+00') TO ('2026-02-01 00:00:00+00');
ALTER TABLE ONLY public.ai_prompt_templates ALTER COLUMN template_id SET DEFAULT nextval('public.ai_prompt_templates_template_id_seq'::regclass);
ALTER TABLE ONLY public.ai_prompt_usage ALTER COLUMN usage_id SET DEFAULT nextval('public.ai_prompt_usage_usage_id_seq'::regclass);
ALTER TABLE ONLY public.ai_usage_logs ALTER COLUMN id SET DEFAULT nextval('public.ai_usage_logs_id_seq'::regclass);
ALTER TABLE ONLY public.audit_logs ALTER COLUMN id SET DEFAULT nextval('public.audit_logs_id_seq'::regclass);
ALTER TABLE ONLY public.code_quality_feedback ALTER COLUMN feedback_id SET DEFAULT nextval('public.code_quality_feedback_feedback_id_seq'::regclass);
ALTER TABLE ONLY public.message_embeddings ALTER COLUMN id SET DEFAULT nextval('public.message_embeddings_id_seq'::regclass);
ALTER TABLE ONLY public.monday_updates_history ALTER COLUMN update_history_id SET DEFAULT nextval('public.monday_updates_history_update_history_id_seq'::regclass);
ALTER TABLE ONLY public.project_context_embeddings ALTER COLUMN id SET DEFAULT nextval('public.project_context_embeddings_id_seq'::regclass);
ALTER TABLE ONLY public.rate_limits ALTER COLUMN rate_limit_id SET DEFAULT nextval('public.rate_limits_rate_limit_id_seq'::regclass);
ALTER TABLE ONLY public.system_users ALTER COLUMN user_id SET DEFAULT nextval('public.system_users_user_id_seq'::regclass);
ALTER TABLE ONLY public.task_context_memory ALTER COLUMN memory_id SET DEFAULT nextval('public.task_context_memory_memory_id_seq'::regclass);
ALTER TABLE ONLY public.task_update_triggers ALTER COLUMN trigger_id SET DEFAULT nextval('public.task_update_triggers_trigger_id_seq'::regclass);
ALTER TABLE ONLY public.users ALTER COLUMN user_id SET DEFAULT nextval('public.users_user_id_seq'::regclass);
ALTER TABLE ONLY public.workflow_cooldowns ALTER COLUMN cooldown_id SET DEFAULT nextval('public.workflow_cooldowns_cooldown_id_seq'::regclass);
ALTER TABLE ONLY public.workflow_locks ALTER COLUMN lock_id SET DEFAULT nextval('public.workflow_locks_lock_id_seq'::regclass);
ALTER TABLE ONLY public.workflow_reactivations ALTER COLUMN id SET DEFAULT nextval('public.workflow_reactivations_id_seq'::regclass);
ALTER TABLE ONLY public.ai_code_generations
    ADD CONSTRAINT ai_code_generations_pkey PRIMARY KEY (ai_code_generations_id);
ALTER TABLE ONLY public.ai_cost_tracking
    ADD CONSTRAINT ai_cost_tracking_pkey PRIMARY KEY (ai_cost_tracking_id);
ALTER TABLE ONLY public.ai_interactions
    ADD CONSTRAINT ai_interactions_pkey PRIMARY KEY (ai_interactions_id);
ALTER TABLE ONLY public.ai_prompt_templates
    ADD CONSTRAINT ai_prompt_templates_pkey PRIMARY KEY (template_id);
ALTER TABLE ONLY public.ai_prompt_templates
    ADD CONSTRAINT ai_prompt_templates_template_name_key UNIQUE (template_name);
ALTER TABLE ONLY public.ai_prompt_usage
    ADD CONSTRAINT ai_prompt_usage_pkey PRIMARY KEY (usage_id);
ALTER TABLE ONLY public.ai_usage_logs
    ADD CONSTRAINT ai_usage_logs_pkey PRIMARY KEY (id);
ALTER TABLE ONLY public.application_logs
    ADD CONSTRAINT application_logs_pkey PRIMARY KEY (application_logs_id);
ALTER TABLE ONLY public.audit_logs
    ADD CONSTRAINT audit_logs_pkey PRIMARY KEY (id);
ALTER TABLE ONLY public.celery_taskmeta
    ADD CONSTRAINT celery_taskmeta_pkey PRIMARY KEY (id);
ALTER TABLE ONLY public.celery_taskmeta
    ADD CONSTRAINT celery_taskmeta_task_id_key UNIQUE (task_id);
ALTER TABLE ONLY public.celery_tasksetmeta
    ADD CONSTRAINT celery_tasksetmeta_pkey PRIMARY KEY (id);
ALTER TABLE ONLY public.celery_tasksetmeta
    ADD CONSTRAINT celery_tasksetmeta_taskset_id_key UNIQUE (taskset_id);
ALTER TABLE ONLY public.code_quality_feedback
    ADD CONSTRAINT code_quality_feedback_pkey PRIMARY KEY (feedback_id);
ALTER TABLE ONLY public.human_validation_responses
    ADD CONSTRAINT human_validation_responses_pkey PRIMARY KEY (human_validation_responses_id);
ALTER TABLE ONLY public.human_validations
    ADD CONSTRAINT human_validations_pkey PRIMARY KEY (human_validations_id);
ALTER TABLE ONLY public.human_validations
    ADD CONSTRAINT human_validations_validation_id_key UNIQUE (validation_id);
ALTER TABLE ONLY public.message_embeddings
    ADD CONSTRAINT message_embeddings_pkey PRIMARY KEY (id);
ALTER TABLE ONLY public.monday_updates_history
    ADD CONSTRAINT monday_updates_history_pkey PRIMARY KEY (update_history_id);
ALTER TABLE ONLY public.performance_metrics
    ADD CONSTRAINT performance_metrics_pkey PRIMARY KEY (performance_metrics_id);
ALTER TABLE ONLY public.project_context_embeddings
    ADD CONSTRAINT project_context_embeddings_pkey PRIMARY KEY (id);
ALTER TABLE ONLY public.pull_requests
    ADD CONSTRAINT pull_requests_pkey PRIMARY KEY (pull_requests_id);
ALTER TABLE ONLY public.rate_limits
    ADD CONSTRAINT rate_limits_pkey PRIMARY KEY (rate_limit_id);
ALTER TABLE ONLY public.run_step_checkpoints
    ADD CONSTRAINT run_step_checkpoints_pkey PRIMARY KEY (checkpoint_id);
ALTER TABLE ONLY public.run_steps
    ADD CONSTRAINT run_steps_pkey PRIMARY KEY (run_steps_id);
ALTER TABLE ONLY public.system_config
    ADD CONSTRAINT system_config_key_key UNIQUE (key);
ALTER TABLE ONLY public.system_config
    ADD CONSTRAINT system_config_pkey PRIMARY KEY (system_config_id);
ALTER TABLE ONLY public.system_users
    ADD CONSTRAINT system_users_email_key UNIQUE (email);
ALTER TABLE ONLY public.system_users
    ADD CONSTRAINT system_users_monday_user_id_key UNIQUE (monday_user_id);
ALTER TABLE ONLY public.system_users
    ADD CONSTRAINT system_users_pkey PRIMARY KEY (user_id);
ALTER TABLE ONLY public.system_users
    ADD CONSTRAINT system_users_username_key UNIQUE (username);
ALTER TABLE ONLY public.task_context_memory
    ADD CONSTRAINT task_context_memory_pkey PRIMARY KEY (memory_id);
ALTER TABLE ONLY public.task_runs
    ADD CONSTRAINT task_runs_celery_task_id_key UNIQUE (celery_task_id);
ALTER TABLE ONLY public.task_runs
    ADD CONSTRAINT task_runs_pkey PRIMARY KEY (tasks_runs_id);
ALTER TABLE ONLY public.task_update_triggers
    ADD CONSTRAINT task_update_triggers_pkey PRIMARY KEY (trigger_id);
ALTER TABLE ONLY public.tasks
    ADD CONSTRAINT tasks_monday_item_id_key UNIQUE (monday_item_id);
ALTER TABLE ONLY public.tasks
    ADD CONSTRAINT tasks_pkey PRIMARY KEY (tasks_id);
ALTER TABLE ONLY public.test_results
    ADD CONSTRAINT test_results_pkey PRIMARY KEY (test_results_id);
ALTER TABLE ONLY public.message_embeddings
    ADD CONSTRAINT unique_message_update UNIQUE (monday_update_id);
ALTER TABLE ONLY public.human_validations
    ADD CONSTRAINT unique_validation_per_run UNIQUE (task_run_id, validation_id);
ALTER TABLE ONLY public.users
    ADD CONSTRAINT users_email_key UNIQUE (email);
ALTER TABLE ONLY public.users
    ADD CONSTRAINT users_pkey PRIMARY KEY (user_id);
ALTER TABLE ONLY public.validation_actions
    ADD CONSTRAINT validation_actions_pkey PRIMARY KEY (validation_actions_id);
ALTER TABLE ONLY public.webhook_events
    ADD CONSTRAINT webhook_events_pkey PRIMARY KEY (webhook_events_id, received_at);
ALTER TABLE ONLY public.webhook_events_2025_09
    ADD CONSTRAINT webhook_events_2025_09_pkey PRIMARY KEY (webhook_events_id, received_at);
ALTER TABLE ONLY public.webhook_events_p2025_10
    ADD CONSTRAINT webhook_events_p2025_10_pkey PRIMARY KEY (webhook_events_id, received_at);
ALTER TABLE ONLY public.webhook_events_p2025_11
    ADD CONSTRAINT webhook_events_p2025_11_pkey PRIMARY KEY (webhook_events_id, received_at);
ALTER TABLE ONLY public.webhook_events_p2025_12
    ADD CONSTRAINT webhook_events_p2025_12_pkey PRIMARY KEY (webhook_events_id, received_at);
ALTER TABLE ONLY public.webhook_events_p2026_01
    ADD CONSTRAINT webhook_events_p2026_01_pkey PRIMARY KEY (webhook_events_id, received_at);
ALTER TABLE ONLY public.workflow_cooldowns
    ADD CONSTRAINT workflow_cooldowns_pkey PRIMARY KEY (cooldown_id);
ALTER TABLE ONLY public.workflow_locks
    ADD CONSTRAINT workflow_locks_pkey PRIMARY KEY (lock_id);
ALTER TABLE ONLY public.workflow_queue
    ADD CONSTRAINT workflow_queue_pkey PRIMARY KEY (queue_id);
ALTER TABLE ONLY public.workflow_reactivations
    ADD CONSTRAINT workflow_reactivations_pkey PRIMARY KEY (id);
CREATE INDEX ai_usage_logs_date_provider_idx ON public.ai_usage_logs USING btree ("timestamp", provider);
CREATE INDEX ai_usage_logs_provider_idx ON public.ai_usage_logs USING btree (provider);
CREATE INDEX ai_usage_logs_task_id_idx ON public.ai_usage_logs USING btree (task_id);
CREATE INDEX ai_usage_logs_timestamp_idx ON public.ai_usage_logs USING btree ("timestamp");
CREATE INDEX ai_usage_logs_workflow_id_idx ON public.ai_usage_logs USING btree (workflow_id);
CREATE INDEX ai_usage_logs_workflow_timestamp_idx ON public.ai_usage_logs USING btree (workflow_id, "timestamp");
CREATE INDEX idx_ai_code_gen_provider ON public.ai_code_generations USING btree (provider, generated_at DESC);
CREATE INDEX idx_ai_code_gen_run ON public.ai_code_generations USING btree (task_run_id);
CREATE INDEX idx_ai_cost_provider_date ON public.ai_cost_tracking USING btree (provider, created_at DESC);
CREATE INDEX idx_ai_cost_run ON public.ai_cost_tracking USING btree (task_run_id);
CREATE INDEX idx_ai_cost_task ON public.ai_cost_tracking USING btree (task_id);
CREATE INDEX idx_ai_interactions_provider ON public.ai_interactions USING btree (ai_provider, created_at DESC);
CREATE INDEX idx_ai_interactions_step ON public.ai_interactions USING btree (run_step_id);
CREATE INDEX idx_ai_prompt_templates_active ON public.ai_prompt_templates USING btree (is_active);
CREATE INDEX idx_ai_prompt_templates_category ON public.ai_prompt_templates USING btree (template_category);
CREATE INDEX idx_ai_usage_logs_cost ON public.ai_usage_logs USING btree (estimated_cost DESC);
CREATE INDEX idx_ai_usage_logs_provider ON public.ai_usage_logs USING btree (provider);
CREATE INDEX idx_ai_usage_logs_run ON public.ai_usage_logs USING btree (task_id);
CREATE INDEX idx_ai_usage_logs_task ON public.ai_usage_logs USING btree (workflow_id);
CREATE INDEX idx_ai_usage_logs_timestamp ON public.ai_usage_logs USING btree ("timestamp");
CREATE INDEX idx_application_logs_component ON public.application_logs USING btree (source_component, ts DESC);
CREATE INDEX idx_application_logs_level ON public.application_logs USING btree (level, ts DESC);
CREATE INDEX idx_application_logs_task ON public.application_logs USING btree (task_id, ts DESC);
CREATE INDEX idx_audit_logs_action ON public.audit_logs USING btree (action);
CREATE INDEX idx_audit_logs_details ON public.audit_logs USING gin (details);
CREATE INDEX idx_audit_logs_severity ON public.audit_logs USING btree (severity);
CREATE INDEX idx_audit_logs_status ON public.audit_logs USING btree (status);
CREATE INDEX idx_audit_logs_timestamp ON public.audit_logs USING btree ("timestamp" DESC);
CREATE INDEX idx_audit_logs_user_id ON public.audit_logs USING btree (user_id);
CREATE INDEX idx_checkpoints_created_at ON public.run_step_checkpoints USING btree (created_at DESC);
CREATE INDEX idx_checkpoints_step_id ON public.run_step_checkpoints USING btree (step_id);
CREATE INDEX idx_human_validation_responses_status ON public.human_validation_responses USING btree (response_status);
CREATE INDEX idx_human_validation_responses_validated_at ON public.human_validation_responses USING btree (validated_at DESC);
CREATE INDEX idx_human_validation_responses_validated_by ON public.human_validation_responses USING btree (validated_by);
CREATE INDEX idx_human_validation_responses_validation_id ON public.human_validation_responses USING btree (validation_id);
CREATE INDEX idx_human_validations_created_at ON public.human_validations USING btree (created_at DESC);
CREATE INDEX idx_human_validations_expires_at ON public.human_validations USING btree (expires_at) WHERE (expires_at IS NOT NULL);
CREATE INDEX idx_human_validations_is_retry ON public.human_validations USING btree (is_retry) WHERE (is_retry = true);
CREATE INDEX idx_human_validations_parent_validation ON public.human_validations USING btree (parent_validation_id) WHERE (parent_validation_id IS NOT NULL);
CREATE INDEX idx_human_validations_rejection_count ON public.human_validations USING btree (rejection_count);
CREATE INDEX idx_human_validations_status ON public.human_validations USING btree (status);
CREATE INDEX idx_human_validations_status_expires ON public.human_validations USING btree (status, expires_at);
CREATE INDEX idx_human_validations_task_id ON public.human_validations USING btree (task_id);
CREATE INDEX idx_human_validations_updated_at ON public.human_validations USING btree (updated_at DESC);
CREATE INDEX idx_human_validations_user_email ON public.human_validations USING btree (user_email);
CREATE INDEX idx_human_validations_validation_id ON public.human_validations USING btree (validation_id);
CREATE INDEX idx_perf_recorded ON public.performance_metrics USING btree (recorded_at DESC);
CREATE INDEX idx_perf_task_run ON public.performance_metrics USING btree (task_id, task_run_id);
CREATE INDEX idx_pr_created ON public.pull_requests USING btree (created_at DESC);
CREATE INDEX idx_pr_number ON public.pull_requests USING btree (github_pr_number);
CREATE INDEX idx_pr_status ON public.pull_requests USING btree (pr_status);
CREATE INDEX idx_pr_task ON public.pull_requests USING btree (task_id);
CREATE INDEX idx_prompt_templates_active ON public.ai_prompt_templates USING btree (is_active);
CREATE INDEX idx_prompt_templates_category ON public.ai_prompt_templates USING btree (template_category);
CREATE INDEX idx_prompt_templates_created ON public.ai_prompt_templates USING btree (created_at);
CREATE INDEX idx_prompt_templates_default ON public.ai_prompt_templates USING btree (is_active) WHERE (is_active = true);
CREATE INDEX idx_prompt_templates_success ON public.ai_prompt_templates USING btree (avg_cost_usd);
CREATE INDEX idx_prompt_usage_cost ON public.ai_prompt_usage USING btree (cost_usd DESC);
CREATE INDEX idx_prompt_usage_date ON public.ai_prompt_usage USING btree (executed_at DESC);
CREATE INDEX idx_prompt_usage_interaction ON public.ai_prompt_usage USING btree (executed_at);
CREATE INDEX idx_prompt_usage_run ON public.ai_prompt_usage USING btree (task_run_id);
CREATE INDEX idx_prompt_usage_success ON public.ai_prompt_usage USING btree (success);
CREATE INDEX idx_prompt_usage_task ON public.ai_prompt_usage USING btree (task_id);
CREATE INDEX idx_prompt_usage_template ON public.ai_prompt_usage USING btree (template_id);
CREATE INDEX idx_prompt_usage_user ON public.ai_prompt_usage USING btree (template_id, executed_at);
CREATE INDEX idx_run_steps_completed ON public.run_steps USING btree (task_run_id, completed_at) WHERE (completed_at IS NOT NULL);
CREATE INDEX idx_run_steps_name_status ON public.run_steps USING btree (node_name, status);
CREATE INDEX idx_run_steps_run_order ON public.run_steps USING btree (task_run_id, step_order);
CREATE INDEX idx_run_steps_started_at ON public.run_steps USING btree (started_at DESC);
CREATE INDEX idx_run_steps_task_run ON public.run_steps USING btree (task_run_id);
CREATE INDEX idx_run_steps_task_run_id ON public.run_steps USING btree (task_run_id);
CREATE INDEX idx_system_config_type ON public.system_config USING btree (config_type);
CREATE INDEX idx_system_users_email ON public.system_users USING btree (email);
CREATE INDEX idx_system_users_is_active ON public.system_users USING btree (is_active);
CREATE INDEX idx_task_runs_browser_qa_results ON public.task_runs USING gin (browser_qa_results);
CREATE INDEX idx_task_runs_celery ON public.task_runs USING btree (celery_task_id);
CREATE INDEX idx_task_runs_completed_at ON public.task_runs USING btree (completed_at DESC);
CREATE INDEX idx_task_runs_completed_only ON public.task_runs USING btree (task_id, completed_at DESC) WHERE (completed_at IS NOT NULL);
CREATE INDEX idx_task_runs_duration_calc ON public.task_runs USING btree (started_at, completed_at) WHERE (completed_at IS NOT NULL);
CREATE INDEX idx_task_runs_is_reactivation ON public.task_runs USING btree (is_reactivation) WHERE (is_reactivation = true);
CREATE INDEX idx_task_runs_parent_run_id ON public.task_runs USING btree (parent_run_id) WHERE (parent_run_id IS NOT NULL);
CREATE INDEX idx_task_runs_reactivation_chain ON public.task_runs USING btree (task_id, parent_run_id, is_reactivation) WHERE (is_reactivation = true);
CREATE INDEX idx_task_runs_reactivation_count ON public.task_runs USING btree (reactivation_count) WHERE (reactivation_count > 0);
CREATE INDEX idx_task_runs_started_at_only ON public.task_runs USING btree (started_at DESC);
CREATE INDEX idx_task_runs_status ON public.task_runs USING btree (status);
CREATE INDEX idx_task_runs_task_id_only ON public.task_runs USING btree (task_id);
CREATE INDEX idx_task_runs_task_started ON public.task_runs USING btree (task_id, started_at DESC);
CREATE INDEX idx_tasks_cooldown_until ON public.tasks USING btree (cooldown_until) WHERE (cooldown_until IS NOT NULL);
CREATE INDEX idx_tasks_created_at ON public.tasks USING btree (created_at DESC);
CREATE INDEX idx_tasks_failed_attempts ON public.tasks USING btree (failed_reactivation_attempts) WHERE (failed_reactivation_attempts > 0);
CREATE INDEX idx_tasks_internal_status_full ON public.tasks USING btree (internal_status);
CREATE INDEX idx_tasks_internal_status_partial ON public.tasks USING btree (internal_status) WHERE ((internal_status)::text = ANY ((ARRAY['pending'::character varying, 'processing'::character varying])::text[]));
CREATE INDEX idx_tasks_is_locked ON public.tasks USING btree (is_locked) WHERE (is_locked = true);
CREATE INDEX idx_tasks_monday_item_id ON public.tasks USING btree (monday_item_id);
CREATE INDEX idx_tasks_priority ON public.tasks USING btree (priority);
CREATE INDEX idx_tasks_priority_status_combo ON public.tasks USING btree (priority, internal_status);
CREATE INDEX idx_tasks_reactivation ON public.tasks USING btree (reactivation_count) WHERE (reactivation_count > 0);
CREATE INDEX idx_tasks_repository ON public.tasks USING btree (repository_url);
CREATE INDEX idx_tasks_status_created_combo ON public.tasks USING btree (internal_status, created_at DESC);
CREATE INDEX idx_test_results_run ON public.test_results USING btree (task_run_id);
CREATE INDEX idx_test_results_status ON public.test_results USING btree (status, executed_at DESC);
CREATE INDEX idx_users_active ON public.users USING btree (is_active);
CREATE INDEX idx_users_email ON public.users USING btree (email);
CREATE INDEX idx_users_role ON public.users USING btree (role);
CREATE INDEX idx_validation_actions_created_at ON public.validation_actions USING btree (created_at DESC);
CREATE INDEX idx_validation_actions_type_status ON public.validation_actions USING btree (action_type, action_status);
CREATE INDEX idx_validation_actions_validation_id ON public.validation_actions USING btree (validation_id);
CREATE INDEX idx_webhook_events_event_type ON ONLY public.webhook_events USING btree (event_type);
CREATE INDEX idx_webhook_events_p2025_10_processed ON public.webhook_events_p2025_10 USING btree (processed, received_at);
CREATE INDEX idx_webhook_events_p2025_10_source ON public.webhook_events_p2025_10 USING btree (source, event_type);
CREATE INDEX idx_webhook_events_p2025_10_task ON public.webhook_events_p2025_10 USING btree (related_task_id);
CREATE INDEX idx_webhook_events_p2025_11_processed ON public.webhook_events_p2025_11 USING btree (processed, received_at);
CREATE INDEX idx_webhook_events_p2025_11_source ON public.webhook_events_p2025_11 USING btree (source, event_type);
CREATE INDEX idx_webhook_events_p2025_11_task ON public.webhook_events_p2025_11 USING btree (related_task_id);
CREATE INDEX idx_webhook_events_p2025_12_processed ON public.webhook_events_p2025_12 USING btree (processed, received_at);
CREATE INDEX idx_webhook_events_p2025_12_source ON public.webhook_events_p2025_12 USING btree (source, event_type);
CREATE INDEX idx_webhook_events_p2025_12_task ON public.webhook_events_p2025_12 USING btree (related_task_id);
CREATE INDEX idx_webhook_events_p2026_01_processed ON public.webhook_events_p2026_01 USING btree (processed, received_at);
CREATE INDEX idx_webhook_events_p2026_01_source ON public.webhook_events_p2026_01 USING btree (source, event_type);
CREATE INDEX idx_webhook_events_p2026_01_task ON public.webhook_events_p2026_01 USING btree (related_task_id);
CREATE INDEX idx_webhook_events_processed ON ONLY public.webhook_events USING btree (processed);
CREATE INDEX idx_webhook_events_processed_2025_09 ON public.webhook_events_2025_09 USING btree (processed, received_at);
CREATE INDEX idx_webhook_events_processed_part ON public.webhook_events_2025_09 USING btree (processed, received_at);
CREATE INDEX idx_webhook_events_received_at ON ONLY public.webhook_events USING btree (received_at DESC);
CREATE INDEX idx_webhook_events_source_2025_09 ON public.webhook_events_2025_09 USING btree (source, event_type);
CREATE INDEX idx_webhook_events_source_part ON public.webhook_events_2025_09 USING btree (source, event_type);
CREATE INDEX idx_workflow_cooldowns_task_id ON public.workflow_cooldowns USING btree (task_id);
CREATE INDEX idx_workflow_cooldowns_until ON public.workflow_cooldowns USING btree (cooldown_until);
CREATE INDEX idx_workflow_locks_is_active ON public.workflow_locks USING btree (is_active);
CREATE INDEX idx_workflow_locks_lock_key ON public.workflow_locks USING btree (lock_key);
CREATE INDEX idx_workflow_locks_task_id ON public.workflow_locks USING btree (task_id);
CREATE INDEX idx_workflow_queue_completed ON public.workflow_queue USING btree (completed_at) WHERE (completed_at IS NOT NULL);
CREATE INDEX idx_workflow_queue_created_at ON public.workflow_queue USING btree (created_at DESC);
CREATE INDEX idx_workflow_queue_monday_item ON public.workflow_queue USING btree (monday_item_id, queued_at);
CREATE INDEX idx_workflow_queue_monday_item_id ON public.workflow_queue USING btree (monday_item_id);
CREATE INDEX idx_workflow_queue_status ON public.workflow_queue USING btree (status, queued_at);
CREATE INDEX idx_workflow_reactivations_created_at ON public.workflow_reactivations USING btree (created_at);
CREATE INDEX idx_workflow_reactivations_reactivated_at ON public.workflow_reactivations USING btree (reactivated_at DESC);
CREATE INDEX idx_workflow_reactivations_status ON public.workflow_reactivations USING btree (status);
CREATE INDEX idx_workflow_reactivations_task_id ON public.workflow_reactivations USING btree (task_id);
CREATE INDEX idx_workflow_reactivations_trigger_type ON public.workflow_reactivations USING btree (trigger_type);
CREATE INDEX idx_workflow_reactivations_update_data ON public.workflow_reactivations USING gin (update_data);
CREATE INDEX idx_workflow_reactivations_workflow_id ON public.workflow_reactivations USING btree (workflow_id);
CREATE INDEX idx_workflow_reactivations_workflow_status ON public.workflow_reactivations USING btree (workflow_id, status);
CREATE INDEX message_embeddings_created_at_idx ON public.message_embeddings USING btree (created_at DESC);
CREATE INDEX message_embeddings_embedding_idx ON public.message_embeddings USING hnsw (embedding public.vector_cosine_ops) WITH (m='16', ef_construction='64');
COMMENT ON INDEX public.message_embeddings_embedding_idx IS 'Index HNSW pour recherche rapide par similarité cosinus';
CREATE INDEX message_embeddings_message_type_idx ON public.message_embeddings USING btree (message_type);
CREATE INDEX message_embeddings_metadata_idx ON public.message_embeddings USING gin (metadata);
CREATE INDEX message_embeddings_monday_item_idx ON public.message_embeddings USING btree (monday_item_id);
CREATE INDEX message_embeddings_task_id_idx ON public.message_embeddings USING btree (task_id);
CREATE INDEX project_context_embeddings_embedding_idx ON public.project_context_embeddings USING hnsw (embedding public.vector_cosine_ops) WITH (m='16', ef_construction='64');
CREATE INDEX project_context_embeddings_repo_idx ON public.project_context_embeddings USING btree (repository_url);
CREATE INDEX project_context_embeddings_type_idx ON public.project_context_embeddings USING btree (context_type);
CREATE UNIQUE INDEX unique_task_reactivation_run ON public.task_runs USING btree (task_id, reactivation_count) WHERE ((is_reactivation = true) AND (task_id IS NOT NULL));
CREATE UNIQUE INDEX uq_task_runs_task_run_number ON public.task_runs USING btree (task_id, run_number);
CREATE INDEX webhook_events_2025_09_event_type_idx ON public.webhook_events_2025_09 USING btree (event_type);
CREATE INDEX webhook_events_2025_09_processed_idx ON public.webhook_events_2025_09 USING btree (processed);
CREATE INDEX webhook_events_2025_09_received_at_idx ON public.webhook_events_2025_09 USING btree (received_at DESC);
CREATE INDEX webhook_events_p2025_10_event_type_idx ON public.webhook_events_p2025_10 USING btree (event_type);
CREATE INDEX webhook_events_p2025_10_processed_idx ON public.webhook_events_p2025_10 USING btree (processed);
CREATE INDEX webhook_events_p2025_10_received_at_idx ON public.webhook_events_p2025_10 USING btree (received_at DESC);
CREATE INDEX webhook_events_p2025_11_event_type_idx ON public.webhook_events_p2025_11 USING btree (event_type);
CREATE INDEX webhook_events_p2025_11_processed_idx ON public.webhook_events_p2025_11 USING btree (processed);
CREATE INDEX webhook_events_p2025_11_received_at_idx ON public.webhook_events_p2025_11 USING btree (received_at DESC);
CREATE INDEX webhook_events_p2025_12_event_type_idx ON public.webhook_events_p2025_12 USING btree (event_type);
CREATE INDEX webhook_events_p2025_12_processed_idx ON public.webhook_events_p2025_12 USING btree (processed);
CREATE INDEX webhook_events_p2025_12_received_at_idx ON public.webhook_events_p2025_12 USING btree (received_at DESC);
CREATE INDEX webhook_events_p2026_01_event_type_idx ON public.webhook_events_p2026_01 USING btree (event_type);
CREATE INDEX webhook_events_p2026_01_processed_idx ON public.webhook_events_p2026_01 USING btree (processed);
CREATE INDEX webhook_events_p2026_01_received_at_idx ON public.webhook_events_p2026_01 USING btree (received_at DESC);
ALTER INDEX public.idx_webhook_events_event_type ATTACH PARTITION public.webhook_events_2025_09_event_type_idx;
ALTER INDEX public.webhook_events_pkey ATTACH PARTITION public.webhook_events_2025_09_pkey;
ALTER INDEX public.idx_webhook_events_processed ATTACH PARTITION public.webhook_events_2025_09_processed_idx;
ALTER INDEX public.idx_webhook_events_received_at ATTACH PARTITION public.webhook_events_2025_09_received_at_idx;
ALTER INDEX public.idx_webhook_events_event_type ATTACH PARTITION public.webhook_events_p2025_10_event_type_idx;
ALTER INDEX public.webhook_events_pkey ATTACH PARTITION public.webhook_events_p2025_10_pkey;
ALTER INDEX public.idx_webhook_events_processed ATTACH PARTITION public.webhook_events_p2025_10_processed_idx;
ALTER INDEX public.idx_webhook_events_received_at ATTACH PARTITION public.webhook_events_p2025_10_received_at_idx;
ALTER INDEX public.idx_webhook_events_event_type ATTACH PARTITION public.webhook_events_p2025_11_event_type_idx;
ALTER INDEX public.webhook_events_pkey ATTACH PARTITION public.webhook_events_p2025_11_pkey;
ALTER INDEX public.idx_webhook_events_processed ATTACH PARTITION public.webhook_events_p2025_11_processed_idx;
ALTER INDEX public.idx_webhook_events_received_at ATTACH PARTITION public.webhook_events_p2025_11_received_at_idx;
ALTER INDEX public.idx_webhook_events_event_type ATTACH PARTITION public.webhook_events_p2025_12_event_type_idx;
ALTER INDEX public.webhook_events_pkey ATTACH PARTITION public.webhook_events_p2025_12_pkey;
ALTER INDEX public.idx_webhook_events_processed ATTACH PARTITION public.webhook_events_p2025_12_processed_idx;
ALTER INDEX public.idx_webhook_events_received_at ATTACH PARTITION public.webhook_events_p2025_12_received_at_idx;
ALTER INDEX public.idx_webhook_events_event_type ATTACH PARTITION public.webhook_events_p2026_01_event_type_idx;
ALTER INDEX public.webhook_events_pkey ATTACH PARTITION public.webhook_events_p2026_01_pkey;
ALTER INDEX public.idx_webhook_events_processed ATTACH PARTITION public.webhook_events_p2026_01_processed_idx;
ALTER INDEX public.idx_webhook_events_received_at ATTACH PARTITION public.webhook_events_p2026_01_received_at_idx;
CREATE TRIGGER check_rejection_limit_trigger BEFORE INSERT OR UPDATE ON public.human_validation_responses FOR EACH ROW EXECUTE FUNCTION public.check_rejection_limit();
CREATE TRIGGER message_embeddings_updated_at_trigger BEFORE UPDATE ON public.message_embeddings FOR EACH ROW EXECUTE FUNCTION public.update_message_embeddings_updated_at();
CREATE TRIGGER sync_validation_status_trigger AFTER INSERT ON public.human_validation_responses FOR EACH ROW EXECUTE FUNCTION public.sync_validation_status();
CREATE TRIGGER touch_system_config_updated_at BEFORE UPDATE ON public.system_config FOR EACH ROW EXECUTE FUNCTION public.trg_touch_updated_at();
CREATE TRIGGER touch_tasks_updated_at BEFORE UPDATE ON public.tasks FOR EACH ROW EXECUTE FUNCTION public.trg_touch_updated_at();
CREATE TRIGGER trg_update_prompt_stats AFTER INSERT ON public.ai_prompt_usage FOR EACH ROW EXECUTE FUNCTION public.update_prompt_template_stats();
CREATE TRIGGER trigger_reset_failed_attempts BEFORE UPDATE ON public.tasks FOR EACH ROW WHEN (((new.internal_status)::text = 'completed'::text)) EXECUTE FUNCTION public.reset_failed_attempts_on_success();
CREATE TRIGGER trigger_update_workflow_queue_timestamp BEFORE UPDATE ON public.workflow_queue FOR EACH ROW EXECUTE FUNCTION public.update_workflow_queue_timestamp();
CREATE TRIGGER trigger_workflow_reactivations_updated_at BEFORE UPDATE ON public.workflow_reactivations FOR EACH ROW EXECUTE FUNCTION public.update_workflow_reactivations_updated_at();
CREATE TRIGGER users_updated_at_trigger BEFORE UPDATE ON public.users FOR EACH ROW EXECUTE FUNCTION public.update_users_updated_at();
ALTER TABLE ONLY public.ai_prompt_usage
    ADD CONSTRAINT ai_prompt_usage_template_id_fkey FOREIGN KEY (template_id) REFERENCES public.ai_prompt_templates(template_id) ON DELETE SET NULL;
ALTER TABLE ONLY public.application_logs
    ADD CONSTRAINT application_logs_run_step_id_fkey FOREIGN KEY (run_step_id) REFERENCES public.run_steps(run_steps_id) ON DELETE SET NULL;
ALTER TABLE ONLY public.application_logs
    ADD CONSTRAINT application_logs_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id) ON DELETE SET NULL;
ALTER TABLE ONLY public.application_logs
    ADD CONSTRAINT application_logs_task_run_id_fkey FOREIGN KEY (task_run_id) REFERENCES public.task_runs(tasks_runs_id) ON DELETE SET NULL;
ALTER TABLE ONLY public.audit_logs
    ADD CONSTRAINT audit_logs_user_id_fkey FOREIGN KEY (user_id) REFERENCES public.users(user_id) ON DELETE SET NULL;
ALTER TABLE ONLY public.code_quality_feedback
    ADD CONSTRAINT code_quality_feedback_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id);
ALTER TABLE ONLY public.code_quality_feedback
    ADD CONSTRAINT code_quality_feedback_task_run_id_fkey FOREIGN KEY (task_run_id) REFERENCES public.task_runs(tasks_runs_id);
ALTER TABLE ONLY public.workflow_reactivations
    ADD CONSTRAINT fk_workflow_reactivations_workflow FOREIGN KEY (workflow_id) REFERENCES public.tasks(tasks_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.human_validation_responses
    ADD CONSTRAINT human_validation_responses_human_validation_id_fkey FOREIGN KEY (human_validation_id) REFERENCES public.human_validations(human_validations_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.human_validations
    ADD CONSTRAINT human_validations_run_step_id_fkey FOREIGN KEY (run_step_id) REFERENCES public.run_steps(run_steps_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.human_validations
    ADD CONSTRAINT human_validations_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.human_validations
    ADD CONSTRAINT human_validations_task_run_id_fkey FOREIGN KEY (task_run_id) REFERENCES public.task_runs(tasks_runs_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.monday_updates_history
    ADD CONSTRAINT monday_updates_history_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id);
ALTER TABLE ONLY public.performance_metrics
    ADD CONSTRAINT performance_metrics_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.performance_metrics
    ADD CONSTRAINT performance_metrics_task_run_id_fkey FOREIGN KEY (task_run_id) REFERENCES public.task_runs(tasks_runs_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.pull_requests
    ADD CONSTRAINT pull_requests_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.pull_requests
    ADD CONSTRAINT pull_requests_task_run_id_fkey FOREIGN KEY (task_run_id) REFERENCES public.task_runs(tasks_runs_id) ON DELETE SET NULL;
ALTER TABLE ONLY public.rate_limits
    ADD CONSTRAINT rate_limits_user_id_fkey FOREIGN KEY (user_id) REFERENCES public.system_users(user_id);
ALTER TABLE ONLY public.run_step_checkpoints
    ADD CONSTRAINT run_step_checkpoints_step_id_fkey FOREIGN KEY (step_id) REFERENCES public.run_steps(run_steps_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.run_steps
    ADD CONSTRAINT run_steps_task_run_id_fkey FOREIGN KEY (task_run_id) REFERENCES public.task_runs(tasks_runs_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.task_context_memory
    ADD CONSTRAINT task_context_memory_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id);
ALTER TABLE ONLY public.task_runs
    ADD CONSTRAINT task_runs_parent_run_id_fkey FOREIGN KEY (parent_run_id) REFERENCES public.task_runs(tasks_runs_id) ON DELETE SET NULL;
ALTER TABLE ONLY public.task_runs
    ADD CONSTRAINT task_runs_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id) ON DELETE SET NULL;
ALTER TABLE ONLY public.task_update_triggers
    ADD CONSTRAINT task_update_triggers_new_run_id_fkey FOREIGN KEY (new_run_id) REFERENCES public.task_runs(tasks_runs_id);
ALTER TABLE ONLY public.task_update_triggers
    ADD CONSTRAINT task_update_triggers_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id);
ALTER TABLE ONLY public.test_results
    ADD CONSTRAINT test_results_task_run_id_fkey FOREIGN KEY (task_run_id) REFERENCES public.task_runs(tasks_runs_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.validation_actions
    ADD CONSTRAINT validation_actions_human_validation_id_fkey FOREIGN KEY (human_validation_id) REFERENCES public.human_validations(human_validations_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.workflow_cooldowns
    ADD CONSTRAINT workflow_cooldowns_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.workflow_locks
    ADD CONSTRAINT workflow_locks_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id) ON DELETE CASCADE;
ALTER TABLE ONLY public.workflow_queue
    ADD CONSTRAINT workflow_queue_task_id_fkey FOREIGN KEY (task_id) REFERENCES public.tasks(tasks_id) ON DELETE SET NULL;
