"""
Monday Evaluation Feedback Service - Service pour renvoyer les scores d'Ã©valuation dans Monday.

ImplÃ©mentation de la boucle de rÃ©troaction:
Update Monday â†’ Agent â†’ Output â†’ LLM Judge + Validation Humaine â†’ ğŸ” Retour Monday

Permet de:
1. Poster les scores LLM dans Monday
2. Poster les validations humaines dans Monday
3. Mettre Ã  jour les colonnes Monday avec les mÃ©triques
4. CrÃ©er des updates de feedback
"""

from typing import Dict, Any, Optional
from datetime import datetime
from tools.monday_tool import MondayTool
from utils.monday_comment_formatter import format_for_monday
from utils.logger import get_logger

logger = get_logger(__name__)


class MondayEvaluationFeedbackService:
    """
    Service pour renvoyer les rÃ©sultats d'Ã©valuation dans Monday.com.
    """
    
    def __init__(self):
        """Initialise le service avec le MondayTool."""
        self.monday_tool = MondayTool()
        logger.info("âœ… MondayEvaluationFeedbackService initialisÃ©")
    
    async def post_llm_evaluation_result(
        self,
        item_id: str,
        evaluation_result: Dict[str, Any],
        tag_user: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Poste le rÃ©sultat de l'Ã©valuation LLM dans Monday.
        
        Args:
            item_id: ID de l'item Monday.
            evaluation_result: RÃ©sultat de l'Ã©valuation (de VyDataEvaluator).
            tag_user: Nom d'utilisateur Ã  taguer (optionnel).
            
        Returns:
            RÃ©sultat de la crÃ©ation de l'update.
        """
        try:
            logger.info(f"ğŸ“¤ Envoi rÃ©sultat Ã©valuation LLM vers Monday (item {item_id})...")
            
            score = evaluation_result['llm_score']
            status = evaluation_result['status']
            test_id = evaluation_result.get('test_id', 'N/A')
            reasoning = evaluation_result.get('llm_reasoning', 'N/A')
            duration = evaluation_result.get('duration_seconds', 0)
            
            score_emoji = self._get_score_emoji(score)
            status_emoji = "âœ…" if status == "PASS" else "âŒ"
            
            message = f"""
ğŸ¤– **Ã‰valuation Automatique LLM Judge**

{status_emoji} **Statut**: {status}
{score_emoji} **Score Global**: {score}/100
ğŸ§ª **Test ID**: {test_id}
â±ï¸ **DurÃ©e**: {duration}s

ğŸ“‹ **Scores par CritÃ¨re**:
"""
            
            criteria_scores = evaluation_result.get('criteria_scores', {})
            if criteria_scores:
                for criterion, crit_score in criteria_scores.items():
                    crit_emoji = self._get_score_emoji(crit_score)
                    message += f"{crit_emoji} {criterion.capitalize()}: {crit_score}/100\n"
            
            message += f"""
ğŸ’¬ **Justification**:
{reasoning}

---
â³ **En attente de validation humaine pour score final**
"""
            
            formatted_message = format_for_monday(message, tag_user=tag_user)
            
            result = await self.monday_tool.create_update(
                item_id=item_id,
                update_body=formatted_message
            )
            
            if result.get("success"):
                logger.info(f"âœ… Ã‰valuation LLM postÃ©e dans Monday (item {item_id})")
                return {
                    "success": True,
                    "update_id": result.get("update_id"),
                    "message": "Ã‰valuation LLM postÃ©e avec succÃ¨s"
                }
            else:
                logger.error(f"âŒ Ã‰chec post Ã©valuation LLM: {result.get('error')}")
                return {
                    "success": False,
                    "error": result.get("error")
                }
        
        except Exception as e:
            logger.error(f"âŒ Erreur post Ã©valuation LLM dans Monday: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    async def post_human_validation_result(
        self,
        item_id: str,
        evaluation_result: Dict[str, Any],
        tag_user: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Poste le rÃ©sultat de la validation humaine dans Monday.
        
        Args:
            item_id: ID de l'item Monday.
            evaluation_result: RÃ©sultat complet avec validation humaine.
            tag_user: Nom d'utilisateur Ã  taguer.
            
        Returns:
            RÃ©sultat de la crÃ©ation de l'update.
        """
        try:
            logger.info(f"ğŸ“¤ Envoi validation humaine vers Monday (item {item_id})...")
            
            llm_score = evaluation_result['llm_score']
            human_score = evaluation_result.get('human_score', 0)
            final_score = evaluation_result['final_score']
            status = evaluation_result['status']
            human_feedback = evaluation_result.get('human_feedback', 'Aucun commentaire')
            test_id = evaluation_result.get('test_id', 'N/A')
            
            final_emoji = self._get_score_emoji(final_score)
            status_emoji = "âœ…" if status == "PASS" else "âŒ"
            
            message = f"""
ğŸ‘¤ **Validation Humaine ComplÃ©tÃ©e**

{status_emoji} **Statut Final**: {status}
{final_emoji} **Score Final**: {final_score}/100
ğŸ§ª **Test ID**: {test_id}

ğŸ“Š **DÃ©tails des Scores**:
ğŸ¤– Score LLM: {llm_score}/100
ğŸ‘¤ Score Humain: {human_score}/100
ğŸ¯ Score Final (60% LLM + 40% Humain): {final_score}/100

ğŸ’¬ **Feedback Humain**:
{human_feedback}

---
âœ… **Ã‰valuation complÃ¨te et validÃ©e**
"""
            
            formatted_message = format_for_monday(message, tag_user=tag_user)
            
            result = await self.monday_tool.create_update(
                item_id=item_id,
                update_body=formatted_message
            )
            
            if result.get("success"):
                logger.info(f"âœ… Validation humaine postÃ©e dans Monday (item {item_id})")
                return {
                    "success": True,
                    "update_id": result.get("update_id"),
                    "message": "Validation humaine postÃ©e avec succÃ¨s"
                }
            else:
                logger.error(f"âŒ Ã‰chec post validation humaine: {result.get('error')}")
                return {
                    "success": False,
                    "error": result.get("error")
                }
        
        except Exception as e:
            logger.error(f"âŒ Erreur post validation humaine dans Monday: {e}", exc_info=True)
            return {
                    "success": False,
                "error": str(e)
            }
    
    async def request_human_validation(
        self,
        item_id: str,
        evaluation_result: Dict[str, Any],
        assigned_to: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Demande une validation humaine dans Monday.
        
        Args:
            item_id: ID de l'item Monday.
            evaluation_result: RÃ©sultat de l'Ã©valuation LLM.
            assigned_to: Utilisateur assignÃ© pour la validation.
            
        Returns:
            RÃ©sultat de la crÃ©ation de la demande.
        """
        try:
            logger.info(f"ğŸ™‹ Demande de validation humaine (item {item_id})...")
            
            score = evaluation_result['llm_score']
            test_id = evaluation_result.get('test_id', 'N/A')
            agent_output = evaluation_result.get('agent_output', '')[:200]  
            
            message = f"""
ğŸ™‹ **Validation Humaine Requise**

ğŸ¤– **Score LLM prÃ©liminaire**: {score}/100
ğŸ§ª **Test ID**: {test_id}

ğŸ“ **AperÃ§u de la rÃ©ponse de l'agent**:
{agent_output}...

---
ğŸ‘‰ **Action requise**: Veuillez Ã©valuer cette rÃ©ponse et fournir:
1. Un score humain (0-100)
2. Vos commentaires/feedback
3. Validation (approve/reject)

â° Le score final sera calculÃ© automatiquement (60% LLM + 40% Humain)
"""
            
            formatted_message = format_for_monday(message, tag_user=assigned_to)
            
            result = await self.monday_tool.create_update(
                item_id=item_id,
                update_body=formatted_message
            )
            
            if result.get("success"):
                logger.info(f"âœ… Demande de validation postÃ©e (item {item_id})")
                return {
                    "success": True,
                    "update_id": result.get("update_id"),
                    "message": "Demande de validation postÃ©e"
                }
            else:
                return {
                    "success": False,
                    "error": result.get("error")
                }
        
        except Exception as e:
            logger.error(f"âŒ Erreur demande validation: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    async def post_performance_summary(
        self,
        item_id: str,
        metrics: Dict[str, Any],
        tag_user: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Poste un rÃ©sumÃ© des mÃ©triques de performance dans Monday.
        
        Args:
            item_id: ID de l'item Monday.
            metrics: MÃ©triques de performance (de GoldenDatasetManager).
            tag_user: Utilisateur Ã  taguer.
            
        Returns:
            RÃ©sultat de la crÃ©ation de l'update.
        """
        try:
            logger.info(f"ğŸ“Š Envoi rÃ©sumÃ© performance vers Monday (item {item_id})...")
            
            total_tests = metrics.get('total_tests_run', 0)
            pass_rate = metrics.get('pass_rate_percent', 0)
            avg_score = metrics.get('avg_final_score', 0)
            reliability = metrics.get('reliability_status', 'unknown')
            date = metrics.get('metric_date', datetime.now().strftime("%Y-%m-%d"))
            
            reliability_emoji = {
                'excellent': 'ğŸŸ¢',
                'good': 'ğŸŸ¡',
                'needs_improvement': 'ğŸ”´'
            }.get(reliability, 'âšª')
            
            message = f"""
ğŸ“Š **RÃ©sumÃ© Performance Agent - {date}**

{reliability_emoji} **Statut FiabilitÃ©**: {reliability.upper()}
ğŸ¯ **Score Moyen**: {avg_score}/100
ğŸ“ˆ **Taux de RÃ©ussite**: {pass_rate}%
ğŸ§ª **Tests ExÃ©cutÃ©s**: {total_tests}

ğŸ“‹ **DÃ©tails**:
âœ… Tests rÃ©ussis: {metrics.get('total_tests_run', 0) * pass_rate // 100}
âŒ Tests Ã©chouÃ©s: {metrics.get('total_tests_run', 0) - (metrics.get('total_tests_run', 0) * pass_rate // 100)}
â³ En attente validation: {metrics.get('tests_pending_validation', 0)}

ğŸ’¬ **Notes**:
{metrics.get('notes', 'Aucune note')}

---
ğŸ“ˆ **Tendance**: {self._get_trend_text(avg_score)}
"""
            
            formatted_message = format_for_monday(message, tag_user=tag_user)
            
            result = await self.monday_tool.create_update(
                item_id=item_id,
                update_body=formatted_message
            )
            
            if result.get("success"):
                logger.info(f"âœ… RÃ©sumÃ© performance postÃ© (item {item_id})")
                return {
                    "success": True,
                    "update_id": result.get("update_id"),
                    "message": "RÃ©sumÃ© performance postÃ©"
                }
            else:
                return {
                    "success": False,
                    "error": result.get("error")
                }
        
        except Exception as e:
            logger.error(f"âŒ Erreur post rÃ©sumÃ© performance: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    @staticmethod
    def _get_score_emoji(score: int) -> str:
        """Retourne un emoji selon le score."""
        if score >= 90:
            return "ğŸŒŸ"
        elif score >= 80:
            return "âœ…"
        elif score >= 70:
            return "ğŸ‘"
        elif score >= 50:
            return "âš ï¸"
        else:
            return "âŒ"
    
    @staticmethod
    def _get_trend_text(score: float) -> str:
        """GÃ©nÃ¨re un texte de tendance selon le score."""
        if score >= 85:
            return "Excellente performance, maintenir le niveau ğŸš€"
        elif score >= 75:
            return "Bonne performance, lÃ©gÃ¨res amÃ©liorations possibles ğŸ“ˆ"
        elif score >= 65:
            return "Performance acceptable, des amÃ©liorations sont nÃ©cessaires ğŸ“Š"
        else:
            return "Performance Ã  amÃ©liorer de maniÃ¨re prioritaire âš ï¸"

