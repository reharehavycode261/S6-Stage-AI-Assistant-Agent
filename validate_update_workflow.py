#!/usr/bin/env python3
"""Script de validation rapide du syst√®me de workflow depuis updates Monday."""

import asyncio
import sys
from typing import Dict, Any

# Couleurs pour l'output
class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    RESET = '\033[0m'

def print_success(msg: str):
    print(f"{Colors.GREEN}‚úÖ {msg}{Colors.RESET}")

def print_error(msg: str):
    print(f"{Colors.RED}‚ùå {msg}{Colors.RESET}")

def print_warning(msg: str):
    print(f"{Colors.YELLOW}‚ö†Ô∏è  {msg}{Colors.RESET}")

def print_info(msg: str):
    print(f"{Colors.BLUE}‚ÑπÔ∏è  {msg}{Colors.RESET}")


async def check_imports():
    """V√©rifie que tous les imports n√©cessaires sont disponibles."""
    print("\n" + "="*60)
    print("1Ô∏è‚É£  V√©rification des imports")
    print("="*60)
    
    try:
        from models.schemas import UpdateType, UpdateIntent, UpdateAnalysisContext
        print_success("Mod√®les de donn√©es import√©s")
    except ImportError as e:
        print_error(f"Erreur import mod√®les: {e}")
        return False
    
    try:
        from services.update_analyzer_service import update_analyzer_service
        print_success("UpdateAnalyzerService import√©")
    except ImportError as e:
        print_error(f"Erreur import UpdateAnalyzerService: {e}")
        return False
    
    try:
        from services.workflow_trigger_service import workflow_trigger_service
        print_success("WorkflowTriggerService import√©")
    except ImportError as e:
        print_error(f"Erreur import WorkflowTriggerService: {e}")
        return False
    
    try:
        from services.database_persistence_service import db_persistence
        print_success("DatabasePersistenceService import√©")
    except ImportError as e:
        print_error(f"Erreur import DatabasePersistenceService: {e}")
        return False
    
    return True


async def check_database():
    """V√©rifie que la base de donn√©es est configur√©e correctement."""
    print("\n" + "="*60)
    print("2Ô∏è‚É£  V√©rification de la base de donn√©es")
    print("="*60)
    
    try:
        from services.database_persistence_service import db_persistence
        
        # Initialiser la connexion
        await db_persistence.initialize()
        print_success("Connexion DB √©tablie")
        
        # V√©rifier que la table existe
        async with db_persistence.db_manager.get_connection() as conn:
            result = await conn.fetchval("""
                SELECT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_name = 'task_update_triggers'
                )
            """)
            
            if result:
                print_success("Table task_update_triggers existe")
            else:
                print_error("Table task_update_triggers n'existe pas")
                print_warning("Ex√©cutez: psql -f data/migration_task_update_triggers.sql")
                return False
            
            # V√©rifier que la colonne triggered_by_update_id existe
            result = await conn.fetchval("""
                SELECT EXISTS (
                    SELECT 1 FROM information_schema.columns 
                    WHERE table_name = 'task_runs' 
                    AND column_name = 'triggered_by_update_id'
                )
            """)
            
            if result:
                print_success("Colonne triggered_by_update_id existe dans task_runs")
            else:
                print_error("Colonne triggered_by_update_id manquante")
                print_warning("Ex√©cutez: psql -f data/migration_task_update_triggers.sql")
                return False
        
        return True
        
    except Exception as e:
        print_error(f"Erreur connexion DB: {e}")
        return False


async def test_update_analyzer():
    """Teste le service d'analyse des updates."""
    print("\n" + "="*60)
    print("3Ô∏è‚É£  Test UpdateAnalyzerService")
    print("="*60)
    
    try:
        from services.update_analyzer_service import update_analyzer_service
        from models.schemas import UpdateType
        
        # Test 1: Nouvelle demande
        print_info("Test 1: D√©tection nouvelle demande")
        context = {
            "task_title": "Dashboard admin",
            "task_status": "completed",
            "original_description": "Cr√©er un dashboard"
        }
        
        # Note: Ce test n√©cessite une cl√© API LLM valide
        try:
            result = await update_analyzer_service.analyze_update_intent(
                "Pouvez-vous ajouter un export CSV ?",
                context
            )
            
            print(f"   Type d√©tect√©: {result.type}")
            print(f"   Confiance: {result.confidence}")
            print(f"   Requires workflow: {result.requires_workflow}")
            
            if result.confidence > 0:
                print_success("Analyse LLM fonctionnelle")
            else:
                print_warning("Analyse retourn√©e mais confiance = 0 (v√©rifier cl√©s API)")
                
        except Exception as e:
            print_warning(f"Analyse LLM a √©chou√© (cl√©s API?): {e}")
            print_info("Le syst√®me utilise un fallback en cas d'erreur LLM")
        
        # Test 2: Classification par mots-cl√©s (sans LLM)
        print_info("Test 2: Classification par mots-cl√©s")
        
        test_cases = [
            ("Merci beaucoup !", UpdateType.AFFIRMATION),
            ("Comment faire ?", UpdateType.QUESTION),
            ("Il y a un bug", UpdateType.BUG_REPORT),
            ("Ajouter une feature", UpdateType.NEW_REQUEST),
        ]
        
        all_passed = True
        for text, expected_type in test_cases:
            detected = update_analyzer_service.classify_update_type(text)
            if detected == expected_type:
                print(f"   ‚úì '{text}' ‚Üí {detected}")
            else:
                print(f"   ‚úó '{text}' ‚Üí {detected} (attendu: {expected_type})")
                all_passed = False
        
        if all_passed:
            print_success("Classification par mots-cl√©s fonctionnelle")
        else:
            print_warning("Certaines classifications ont √©chou√©")
        
        return True
        
    except Exception as e:
        print_error(f"Erreur test UpdateAnalyzer: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_workflow_trigger():
    """Teste le service de d√©clenchement de workflow."""
    print("\n" + "="*60)
    print("4Ô∏è‚É£  Test WorkflowTriggerService")
    print("="*60)
    
    try:
        from services.workflow_trigger_service import workflow_trigger_service
        from models.schemas import UpdateIntent, UpdateType
        
        # Test: Cr√©ation de TaskRequest
        print_info("Test: Cr√©ation TaskRequest depuis update")
        
        original_task = {
            'tasks_id': 1,
            'monday_item_id': 12345,
            'title': 'Test task',
            'description': 'Description test',
            'repository_url': 'https://github.com/test/repo',
            'internal_status': 'completed',
            'monday_status': 'Done',
            'priority': 'medium',
            'task_type': 'feature'
        }
        
        update_analysis = UpdateIntent(
            type=UpdateType.NEW_REQUEST,
            confidence=0.92,
            requires_workflow=True,
            reasoning="Test",
            extracted_requirements={
                'title': 'Test feature',
                'description': 'Test description',
                'task_type': 'feature',
                'priority': 'high'
            }
        )
        
        task_request = await workflow_trigger_service.create_task_request_from_update(
            original_task,
            update_analysis
        )
        
        if task_request:
            print(f"   Titre: {task_request.title}")
            print(f"   Type: {task_request.task_type}")
            print(f"   Priorit√©: {task_request.priority}")
            print_success("Cr√©ation TaskRequest fonctionnelle")
        else:
            print_error("√âchec cr√©ation TaskRequest")
            return False
        
        # Test: D√©termination priorit√©
        print_info("Test: D√©termination priorit√© Celery")
        priorities = {
            'urgent': 9,
            'high': 7,
            'medium': 5,
            'low': 3
        }
        
        all_correct = True
        for priority_name, expected_value in priorities.items():
            analysis = UpdateIntent(
                type=UpdateType.NEW_REQUEST,
                confidence=0.9,
                requires_workflow=True,
                reasoning="Test",
                extracted_requirements={'priority': priority_name}
            )
            actual_value = workflow_trigger_service._determine_priority(analysis)
            if actual_value == expected_value:
                print(f"   ‚úì {priority_name} ‚Üí {actual_value}")
            else:
                print(f"   ‚úó {priority_name} ‚Üí {actual_value} (attendu: {expected_value})")
                all_correct = False
        
        if all_correct:
            print_success("D√©termination priorit√© fonctionnelle")
        else:
            print_warning("Certaines priorit√©s incorrectes")
        
        return True
        
    except Exception as e:
        print_error(f"Erreur test WorkflowTrigger: {e}")
        import traceback
        traceback.print_exc()
        return False


async def check_database_methods():
    """V√©rifie que les nouvelles m√©thodes DB fonctionnent."""
    print("\n" + "="*60)
    print("5Ô∏è‚É£  Test m√©thodes DB")
    print("="*60)
    
    try:
        from services.database_persistence_service import db_persistence
        
        # V√©rifier que les m√©thodes existent
        required_methods = [
            'create_update_trigger',
            'mark_trigger_as_processed',
            'get_task_update_triggers',
            'get_update_trigger_stats'
        ]
        
        for method_name in required_methods:
            if hasattr(db_persistence, method_name):
                print(f"   ‚úì {method_name}")
            else:
                print(f"   ‚úó {method_name} manquante")
                return False
        
        print_success("Toutes les m√©thodes DB pr√©sentes")
        
        # Test stats (m√™me si vide)
        print_info("Test: R√©cup√©ration stats (peut √™tre vide)")
        try:
            stats = await db_persistence.get_update_trigger_stats()
            print(f"   Total triggers: {stats.get('total', 0)}")
            print_success("M√©thode get_update_trigger_stats fonctionnelle")
        except Exception as e:
            print_error(f"Erreur get_update_trigger_stats: {e}")
            return False
        
        return True
        
    except Exception as e:
        print_error(f"Erreur test m√©thodes DB: {e}")
        return False


async def run_validation():
    """Ex√©cute toute la validation."""
    print("\n" + "="*60)
    print("üöÄ VALIDATION SYST√àME WORKFLOW DEPUIS UPDATES")
    print("="*60)
    
    results = []
    
    # 1. Imports
    result = await check_imports()
    results.append(("Imports", result))
    if not result:
        print_error("Validation arr√™t√©e: imports manquants")
        return False
    
    # 2. Base de donn√©es
    result = await check_database()
    results.append(("Base de donn√©es", result))
    if not result:
        print_error("Validation arr√™t√©e: DB non configur√©e")
        return False
    
    # 3. UpdateAnalyzerService
    result = await test_update_analyzer()
    results.append(("UpdateAnalyzerService", result))
    
    # 4. WorkflowTriggerService
    result = await test_workflow_trigger()
    results.append(("WorkflowTriggerService", result))
    
    # 5. M√©thodes DB
    result = await check_database_methods()
    results.append(("M√©thodes DB", result))
    
    # R√©sum√©
    print("\n" + "="*60)
    print("üìä R√âSUM√â DE LA VALIDATION")
    print("="*60)
    
    for name, passed in results:
        if passed:
            print_success(f"{name}")
        else:
            print_error(f"{name}")
    
    all_passed = all(result for _, result in results)
    
    if all_passed:
        print("\n" + "="*60)
        print_success("VALIDATION COMPL√àTE R√âUSSIE ‚ú®")
        print_info("Le syst√®me est pr√™t pour les tests manuels")
        print_info("Consultez: GUIDE_TEST_NOUVEAU_WORKFLOW_UPDATE.md")
        print("="*60)
        return True
    else:
        print("\n" + "="*60)
        print_error("VALIDATION √âCHOU√âE")
        print_warning("Corrigez les erreurs avant de continuer")
        print("="*60)
        return False


if __name__ == "__main__":
    try:
        success = asyncio.run(run_validation())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Validation interrompue")
        sys.exit(1)
    except Exception as e:
        print_error(f"Erreur fatale: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

