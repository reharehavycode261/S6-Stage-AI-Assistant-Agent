import os
from enum import Enum
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI

from config.settings import get_settings
from utils.logger import get_logger

logger = get_logger(__name__)
settings = get_settings()


def _scan_project_files(working_dir: str) -> Optional[Dict[str, Any]]:

    try:
        import glob
        from pathlib import Path

        ignored_dirs = {'.git', 'node_modules', '__pycache__', 'venv', 'env', '.venv', 
                        'dist', 'build', 'target', '.idea', '.vscode', 'coverage'}
        
        all_files = []
        technologies = set()

        for root, dirs, files in os.walk(working_dir):

            dirs[:] = [d for d in dirs if d not in ignored_dirs]
            
            for file in files:
                if file.startswith('.'):
                    continue
                    
                full_path = os.path.join(root, file)
                rel_path = os.path.relpath(full_path, working_dir)
                all_files.append(rel_path)
                
                ext = Path(file).suffix.lower()
                if ext in ['.java', '.jar']:
                    technologies.add('Java')
                elif ext in ['.py', '.pyw']:
                    technologies.add('Python')
                elif ext in ['.js', '.jsx', '.ts', '.tsx']:
                    technologies.add('JavaScript/TypeScript')
                elif ext in ['.go']:
                    technologies.add('Go')
                elif ext in ['.rs']:
                    technologies.add('Rust')
                elif ext in ['.rb']:
                    technologies.add('Ruby')
                elif ext in ['.php']:
                    technologies.add('PHP')
                elif ext in ['.c', '.cpp', '.h', '.hpp']:
                    technologies.add('C/C++')
                elif ext in ['.cs']:
                    technologies.add('C#')
                elif ext in ['.swift']:
                    technologies.add('Swift')
                elif ext in ['.kt', '.kts']:
                    technologies.add('Kotlin')
                elif file in ['pom.xml', 'build.gradle', 'build.gradle.kts']:
                    technologies.add('Java/Maven/Gradle')
                elif file in ['package.json', 'yarn.lock', 'package-lock.json']:
                    technologies.add('Node.js/npm')
                elif file in ['requirements.txt', 'setup.py', 'Pipfile', 'pyproject.toml']:
                    technologies.add('Python')
                elif file in ['Cargo.toml', 'Cargo.lock']:
                    technologies.add('Rust')
                elif file in ['go.mod', 'go.sum']:
                    technologies.add('Go')
        
        source_extensions = {'.java', '.py', '.js', '.ts', '.go', '.rs', '.rb', '.php', 
                            '.c', '.cpp', '.cs', '.swift', '.kt'}
        main_files = sorted(all_files, key=lambda f: (
            0 if Path(f).suffix.lower() in source_extensions else 1,
            f
        ))
        
        return {
            'total_files': len(all_files),
            'main_files': main_files,
            'technologies': sorted(list(technologies)),
            'summary': f"{len(all_files)} fichier(s) trouv√©(s)"
        }
    
    except Exception as e:
        logger.error(f"‚ùå Erreur scan fichiers: {e}", exc_info=True)
        return None


class TaskComplexity(str, Enum):
    TRIVIAL = "trivial"
    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"
    VERY_COMPLEX = "very_complex"


class RiskLevel(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class FileValidationStatus(str, Enum):
    VALID = "valid"
    NOT_FOUND = "not_found"
    UNCERTAIN = "uncertain"


class CandidateFile(BaseModel):
    path: str = Field(description="Chemin du fichier")
    action: str = Field(description="Action √† effectuer (create, modify, delete)")
    reason: str = Field(description="Raison de la modification")
    validation_status: FileValidationStatus = Field(
        default=FileValidationStatus.UNCERTAIN,
        description="Statut de validation du fichier"
    )


class TaskDependency(BaseModel):
    name: str = Field(description="Nom de la d√©pendance")
    type: str = Field(description="Type (package, service, file, etc.)")
    version: Optional[str] = Field(default=None, description="Version requise si applicable")
    required: bool = Field(default=True, description="Si la d√©pendance est obligatoire")


class IdentifiedRisk(BaseModel):
    description: str = Field(description="Description du risque")
    level: RiskLevel = Field(description="Niveau de gravit√© du risque")
    mitigation: str = Field(description="Strat√©gie de mitigation propos√©e")
    probability: int = Field(ge=1, le=10, description="Probabilit√© d'occurrence (1-10)")


class Ambiguity(BaseModel):
    question: str = Field(description="Question ou point ambigu")
    impact: str = Field(description="Impact de cette ambigu√Øt√©")
    suggested_assumption: Optional[str] = Field(
        default=None,
        description="Hypoth√®se sugg√©r√©e si pas de clarification"
    )


class RequirementsAnalysis(BaseModel):
    schema_version: int = Field(default=1, description="Version du sch√©ma")

    task_summary: str = Field(description="R√©sum√© de la t√¢che analys√©e")

    complexity: TaskComplexity = Field(description="Complexit√© estim√©e de la t√¢che")
    complexity_score: int = Field(
        ge=1,
        le=10,
        description="Score de complexit√© (1=tr√®s simple, 10=tr√®s complexe)"
    )

    estimated_duration_minutes: int = Field(
        ge=5,
        description="Dur√©e estim√©e en minutes"
    )

    candidate_files: List[CandidateFile] = Field(
        default_factory=list,
        description="Fichiers identifi√©s pour modification"
    )

    dependencies: List[TaskDependency] = Field(
        default_factory=list,
        description="D√©pendances identifi√©es"
    )

    risks: List[IdentifiedRisk] = Field(
        default_factory=list,
        description="Risques identifi√©s"
    )

    ambiguities: List[Ambiguity] = Field(
        default_factory=list,
        description="Ambigu√Øt√©s ou points n√©cessitant clarification"
    )

    missing_info: List[str] = Field(
        default_factory=list,
        description="Informations manquantes pour une impl√©mentation optimale"
    )

    implementation_approach: str = Field(
        description="Approche d'impl√©mentation recommand√©e"
    )

    test_strategy: str = Field(
        description="Strat√©gie de test recommand√©e"
    )

    breaking_changes_risk: bool = Field(
        default=False,
        description="Si l'impl√©mentation risque de casser du code existant"
    )

    requires_external_deps: bool = Field(
        default=False,
        description="Si l'impl√©mentation n√©cessite des d√©pendances externes"
    )

    quality_score: Optional[float] = Field(
        default=None,
        ge=0.0,
        le=1.0,
        description="Score de qualit√© de l'analyse (coverage)"
    )

    class Config:
        json_schema_extra = {
            "example": {
                "schema_version": 1,
                "task_summary": "Cr√©er une API REST pour g√©rer les utilisateurs",
                "complexity": "moderate",
                "complexity_score": 6,
                "estimated_duration_minutes": 45,
                "candidate_files": [
                    {
                        "path": "api/routes/users.py",
                        "action": "create",
                        "reason": "Nouvelles routes API utilisateurs",
                        "validation_status": "uncertain"
                    }
                ],
                "dependencies": [
                    {
                        "name": "fastapi",
                        "type": "package",
                        "version": ">=0.104.0",
                        "required": True
                    }
                ],
                "risks": [
                    {
                        "description": "Conflit avec routes existantes",
                        "level": "medium",
                        "mitigation": "V√©rifier les routes avant impl√©mentation",
                        "probability": 5
                    }
                ],
                "ambiguities": [],
                "missing_info": ["Sch√©ma de validation exact pour User"],
                "implementation_approach": "Cr√©er module API s√©par√© avec validation Pydantic",
                "test_strategy": "Tests unitaires + tests d'int√©gration API",
                "breaking_changes_risk": False,
                "requires_external_deps": False,
                "quality_score": 0.85
            }
        }


def create_requirements_analysis_chain(
    provider: str = "anthropic",
    model: Optional[str] = None,
    temperature: float = 0.1,
    max_tokens: int = 4000,
    max_retries: int = 2
):
    """
    Cr√©e une cha√Æne LCEL pour analyser les requirements de mani√®re structur√©e.

    Args:
        provider: Provider LLM √† utiliser ("anthropic" ou "openai")
        model: Nom du mod√®le (optionnel, utilise le d√©faut du provider)
        temperature: Temp√©rature du mod√®le (0.0-1.0)
        max_tokens: Nombre maximum de tokens
        max_retries: Nombre de tentatives en cas d'√©chec de validation

    Returns:
        Cha√Æne LCEL configur√©e (Prompt ‚Üí LLM ‚Üí Parser)

    Raises:
        ValueError: Si le provider n'est pas support√©
        Exception: Si les cl√©s API sont manquantes
    """
    logger.info(f"üîó Cr√©ation requirements_analysis_chain avec provider={provider}")

    parser = PydanticOutputParser(pydantic_object=RequirementsAnalysis)

    prompt_template = ChatPromptTemplate.from_messages([
        ("system", """Tu es un analyste technique expert qui analyse les requirements de projets logiciels.
Tu dois examiner la description de la t√¢che et g√©n√©rer une analyse structur√©e compl√®te au format JSON strict.

IMPORTANT: Tu DOIS retourner UNIQUEMENT du JSON valide, sans texte avant ou apr√®s.
Utilise le sch√©ma suivant:

{format_instructions}

Sois exhaustif dans ton analyse :
- Identifie TOUS les fichiers potentiellement concern√©s
- Liste TOUTES les d√©pendances n√©cessaires
- D√©tecte TOUS les risques possibles
- Signale TOUTES les ambigu√Øt√©s ou informations manquantes
- Estime la complexit√© de fa√ßon r√©aliste
- Propose une strat√©gie d'impl√©mentation claire

‚úÖ R√àGLES IMPORTANTES pour r√©duire les informations manquantes :
1. Si une information n'est pas fournie, propose une valeur par d√©faut raisonnable
2. Pour les crit√®res d'acceptation manquants, d√©duis-les du titre et de la description
3. Pour le contexte technique manquant, assume un contexte standard selon le type de projet
4. Pour les d√©pendances, liste les d√©pendances courantes m√™me si non mentionn√©es explicitement
5. Privil√©gie des estimations conservatrices plut√¥t que de signaler des manques"""),
        ("user", """Analyse cette t√¢che en d√©tail:

## INFORMATIONS DE LA T√ÇCHE

**Titre**: {task_title}
**Type**: {task_type}
**Priorit√©**: {priority}

**Description**:
{description}

**Crit√®res d'acceptation**:
{acceptance_criteria}

**Contexte technique**:
{technical_context}

**Fichiers mentionn√©s**:
{files_to_modify}

**Repository**: {repository_url}

## CONTEXTE ADDITIONNEL
{additional_context}

G√©n√®re une analyse compl√®te et structur√©e de cette t√¢che.""")
    ])

    prompt = prompt_template.partial(format_instructions=parser.get_format_instructions())

    if provider.lower() == "anthropic":
        if not settings.anthropic_api_key:
            raise Exception("ANTHROPIC_API_KEY manquante dans la configuration")

        llm = ChatAnthropic(
            model=model or "claude-3-5-sonnet-20241022",
            anthropic_api_key=settings.anthropic_api_key,
            temperature=temperature,
            max_tokens=max_tokens,
            max_retries=max_retries
        )
        logger.info(f"‚úÖ LLM Anthropic initialis√©: {model or 'claude-3-5-sonnet-20241022'}")

    elif provider.lower() == "openai":
        if not settings.openai_api_key:
            raise Exception("OPENAI_API_KEY manquante dans la configuration")

        llm = ChatOpenAI(
            model=model or "gpt-4",
            openai_api_key=settings.openai_api_key,
            temperature=temperature,
            max_tokens=max_tokens,
            max_retries=max_retries
        )
        logger.info(f"‚úÖ LLM OpenAI initialis√©: {model or 'gpt-4'}")

    else:
        raise ValueError(f"Provider non support√©: {provider}. Utilisez 'anthropic' ou 'openai'")

    chain = prompt | llm | parser

    logger.info("‚úÖ Requirements analysis chain cr√©√©e avec succ√®s")
    return chain


async def generate_requirements_analysis(
    task_title: str,
    task_description: str,
    task_type: str = "feature",
    priority: str = "medium",
    acceptance_criteria: Optional[str] = None,
    technical_context: Optional[str] = None,
    files_to_modify: Optional[List[str]] = None,
    repository_url: Optional[str] = None,
    working_dir: Optional[str] = None,
    additional_context: Optional[Dict[str, Any]] = None,
    provider: str = "anthropic",
    fallback_to_openai: bool = True,
    validate_files: bool = True,
    run_step_id: Optional[int] = None
) -> RequirementsAnalysis:
    """
    G√©n√®re une analyse structur√©e des requirements avec fallback automatique.

    Args:
        task_title: Titre de la t√¢che
        task_description: Description d√©taill√©e
        task_type: Type de t√¢che (feature, bugfix, refactor, etc.)
        priority: Priorit√© de la t√¢che
        acceptance_criteria: Crit√®res d'acceptation
        technical_context: Contexte technique additionnel
        files_to_modify: Liste des fichiers √† modifier (si connus)
        repository_url: URL du repository
        working_dir: R√©pertoire de travail o√π le repository est clon√© (pour scanner les fichiers)
        additional_context: Contexte additionnel (dict)
        provider: Provider principal ("anthropic" ou "openai")
        fallback_to_openai: Si True, fallback vers OpenAI si le provider principal √©choue
        validate_files: Si True, valide l'existence des fichiers candidats
        run_step_id: ID du step pour logger les interactions IA dans la DB

    Returns:
        RequirementsAnalysis valid√© par Pydantic

    Raises:
        Exception: Si tous les providers √©chouent
    """
    context_str = str(additional_context) if additional_context else "Aucun contexte additionnel"
    files_str = ", ".join(files_to_modify) if files_to_modify else "Non sp√©cifi√©s"
    
    project_structure_str = "Non disponible"
    logger.info(f"üîç working_dir fourni: {working_dir}")
    
    if working_dir:
        logger.info(f"‚úÖ working_dir existe: {os.path.exists(working_dir)}")
        if os.path.exists(working_dir):
            try:
                logger.info(f"üîç Scan des fichiers dans: {working_dir}")
                project_structure = _scan_project_files(working_dir)
                logger.info(f"üìä R√©sultat scan: {project_structure}")
                
                if project_structure:
                    project_structure_str = f"""
üìÅ Structure du projet d√©tect√©e:
{project_structure['summary']}

Principaux fichiers:
{chr(10).join(f"  - {f}" for f in project_structure['main_files'][:20])}

Technologies d√©tect√©es: {', '.join(project_structure['technologies']) if project_structure['technologies'] else 'Aucune'}
"""
                    logger.info(f"‚úÖ {project_structure['total_files']} fichiers d√©tect√©s dans {working_dir}")
                else:
                    logger.warning("‚ö†Ô∏è Scan retourn√© None")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors du scan des fichiers: {e}", exc_info=True)
        else:
            logger.warning(f"‚ö†Ô∏è working_dir n'existe pas: {working_dir}")
    else:
        logger.warning("‚ö†Ô∏è Aucun working_dir fourni")

    inputs = {
        "task_title": task_title,
        "description": task_description,
        "task_type": task_type,
        "priority": priority,
        "acceptance_criteria": acceptance_criteria or "Non sp√©cifi√©s",
        "technical_context": f"{technical_context or 'Non sp√©cifi√©'}\n\n{project_structure_str}",
        "files_to_modify": files_str,
        "repository_url": repository_url or "Non sp√©cifi√©",
        "additional_context": context_str
    }

    callbacks = []
    if run_step_id:
        from utils.langchain_db_callback import create_db_callback
        callbacks = [create_db_callback(run_step_id)]
        logger.debug(f"üìù Callback DB activ√© pour run_step_id={run_step_id}")

    try:
        logger.info(f"üöÄ G√©n√©ration analyse requirements avec {provider}...")
        chain = create_requirements_analysis_chain(provider=provider)
        analysis = await chain.ainvoke(inputs, config={"callbacks": callbacks})

        if validate_files and analysis.candidate_files:
            _validate_candidate_files(analysis.candidate_files)

        analysis.quality_score = _calculate_quality_score(analysis)

        logger.info(
            f"‚úÖ Analyse g√©n√©r√©e avec succ√®s: "
            f"{len(analysis.candidate_files)} fichiers, "
            f"{len(analysis.risks)} risques, "
            f"{len(analysis.ambiguities)} ambigu√Øt√©s, "
            f"quality_score={analysis.quality_score:.2f}"
        )
        return analysis

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è √âchec g√©n√©ration analyse avec {provider}: {e}")

        if fallback_to_openai and provider.lower() != "openai":
            try:
                logger.info("üîÑ Fallback vers OpenAI...")
                chain_fallback = create_requirements_analysis_chain(provider="openai")
                analysis = await chain_fallback.ainvoke(inputs, config={"callbacks": callbacks})

                if validate_files and analysis.candidate_files:
                    _validate_candidate_files(analysis.candidate_files)

                analysis.quality_score = _calculate_quality_score(analysis)

                logger.info("‚úÖ Analyse g√©n√©r√©e avec succ√®s (fallback OpenAI)")
                return analysis

            except Exception as fallback_error:
                logger.error(f"‚ùå Fallback OpenAI √©chou√©: {fallback_error}")
                raise Exception(
                    f"Tous les providers ont √©chou√©. "
                    f"Principal: {e}, Fallback: {fallback_error}"
                )

        raise Exception(f"G√©n√©ration analyse √©chou√©e avec {provider}: {e}")


def _validate_candidate_files(files: List[CandidateFile]):
    """
    Valide l'existence des fichiers candidats.

    Args:
        files: Liste des fichiers candidats √† valider
    """
    for file in files:
        if file.action in ["modify", "delete"]:
            if os.path.exists(file.path):
                file.validation_status = FileValidationStatus.VALID
            else:
                file.validation_status = FileValidationStatus.NOT_FOUND
                logger.warning(f"‚ö†Ô∏è Fichier non trouv√©: {file.path}")
        elif file.action == "create":
            if os.path.exists(file.path):
                file.validation_status = FileValidationStatus.UNCERTAIN
                logger.warning(f"‚ö†Ô∏è Fichier √† cr√©er existe d√©j√†: {file.path}")
            else:
                file.validation_status = FileValidationStatus.VALID


def _calculate_quality_score(analysis: RequirementsAnalysis) -> float:
    """
    Calcule un score de qualit√© pour l'analyse.

    ‚úÖ AM√âLIORATION: Seuil de qualit√© augment√© (0.70 ‚Üí 0.80)

    Le score est bas√© sur:
    - Pr√©sence et validit√© des fichiers candidats
    - Identification de risques
    - Gestion des d√©pendances
    - Compl√©tude de l'analyse
    - Clart√© des requirements (p√©nalit√©s pour ambigu√Øt√©s)

    Args:
        analysis: Analyse √† √©valuer

    Returns:
        Score entre 0.0 et 1.0 (minimum recommand√©: 0.80)
    """
    score = 0.0

    if analysis.candidate_files:
        valid_files = sum(
            1 for f in analysis.candidate_files
            if f.validation_status == FileValidationStatus.VALID
        )
        uncertain_files = sum(
            1 for f in analysis.candidate_files
            if f.validation_status == FileValidationStatus.UNCERTAIN
        )
        total_files = len(analysis.candidate_files)

        if uncertain_files == total_files:
            file_score = 0.30  
            logger.info(f"üìã {total_files} fichiers identifi√©s (validation en attente)")
        else:
            file_score = (valid_files / total_files) * 0.35
            if valid_files == total_files and total_files >= 2:
                file_score += 0.05  

        score += min(0.40, file_score)
    else:
        logger.warning("‚ö†Ô∏è Aucun fichier candidat identifi√© - qualit√© r√©duite")

    if analysis.risks:
        risk_score = min(0.15, len(analysis.risks) * 0.04)
        score += risk_score

    if analysis.dependencies:
        dep_score = min(0.15, len(analysis.dependencies) * 0.04)
        score += dep_score

    completeness = 0.0
    if analysis.implementation_approach and len(analysis.implementation_approach) > 20:
        completeness += 0.15  # Augment√© de 0.10
    if analysis.test_strategy and len(analysis.test_strategy) > 15:
        completeness += 0.15  # Augment√© de 0.10
    if analysis.estimated_duration_minutes > 0:
        completeness += 0.10
    score += completeness

    penalties = 0.0

    if analysis.ambiguities and len(analysis.ambiguities) > 3:
        penalties += min(0.10, (len(analysis.ambiguities) - 3) * 0.03)
        logger.warning(f"‚ö†Ô∏è {len(analysis.ambiguities)} ambigu√Øt√©s d√©tect√©es - p√©nalit√© appliqu√©e")

    if analysis.missing_info and len(analysis.missing_info) > 4:  
        penalties += min(0.08, (len(analysis.missing_info) - 4) * 0.02)  
        logger.warning(f"‚ö†Ô∏è {len(analysis.missing_info)} informations manquantes - p√©nalit√© r√©duite appliqu√©e")

    score = max(0.0, score - penalties)

    final_score = min(1.0, score)
    if final_score < 0.75:  
        logger.warning(
            f"‚ö†Ô∏è Score de qualit√© insuffisant: {final_score:.2f} < 0.75 "
            f"(fichiers: {len(analysis.candidate_files) if analysis.candidate_files else 0}, "
            f"ambigu√Øt√©s: {len(analysis.ambiguities)}, "
            f"infos manquantes: {len(analysis.missing_info)})"
        )
    elif final_score < 0.85:
        logger.info(
            f"üìä Score de qualit√© acceptable: {final_score:.2f} "
            f"(fichiers: {len(analysis.candidate_files) if analysis.candidate_files else 0}, "
            f"ambigu√Øt√©s: {len(analysis.ambiguities)}, "
            f"infos manquantes: {len(analysis.missing_info)})"
        )

    return final_score


def extract_analysis_metrics(analysis: RequirementsAnalysis) -> Dict[str, Any]:
    valid_files = sum(
        1 for f in analysis.candidate_files
        if f.validation_status == FileValidationStatus.VALID
    )

    high_risks = sum(
        1 for r in analysis.risks
        if r.level in [RiskLevel.HIGH, RiskLevel.CRITICAL]
    )

    return {
        "schema_version": analysis.schema_version,
        "complexity": analysis.complexity.value,
        "complexity_score": analysis.complexity_score,
        "estimated_duration_minutes": analysis.estimated_duration_minutes,
        "total_files": len(analysis.candidate_files),
        "valid_files": valid_files,
        "invalid_files": len(analysis.candidate_files) - valid_files,
        "file_coverage": valid_files / len(analysis.candidate_files) if analysis.candidate_files else 0,
        "total_dependencies": len(analysis.dependencies),
        "required_dependencies": sum(1 for d in analysis.dependencies if d.required),
        "total_risks": len(analysis.risks),
        "high_risks": high_risks,
        "risk_percentage": (high_risks / len(analysis.risks) * 100) if analysis.risks else 0,
        "total_ambiguities": len(analysis.ambiguities),
        "missing_info_count": len(analysis.missing_info),
        "quality_score": analysis.quality_score or 0.0,
        "breaking_changes_risk": analysis.breaking_changes_risk,
        "requires_external_deps": analysis.requires_external_deps
    }
