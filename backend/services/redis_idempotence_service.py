"""
Service Redis pour l'idempotence et la d√©duplication des webhooks.

Ce service g√®re:
- D√©duplication des webhooks Monday.com
- Cache des contextes courts
- TTL automatique (1h par d√©faut)
"""

import json
from typing import Optional, Dict, Any
from datetime import timedelta
import redis.asyncio as aioredis
from utils.logger import get_logger
from config.settings import get_settings

logger = get_logger(__name__)
settings = get_settings()


class RedisIdempotenceService:
    """
    Service Redis pour g√©rer l'idempotence des webhooks.
    
    Cl√©s Redis utilis√©es:
    - update:{update_id} ‚Üí Webhook update trait√© (TTL 1h)
    - webhook:{item_id}:{event_type} ‚Üí √âv√©nement webhook (TTL 1h)
    - context:{task_id} ‚Üí Contexte court de t√¢che (TTL 1h)
    """
    
    def __init__(self):
        """Initialise le service Redis."""
        self.redis_client: Optional[aioredis.Redis] = None
        self._initialized = False
    
    async def initialize(self):
        """Initialise la connexion Redis."""
        if self._initialized:
            return
        
        try:
            self.redis_client = await aioredis.from_url(
                settings.redis_url,
                encoding="utf-8",
                decode_responses=True,
                socket_timeout=5.0,
                socket_connect_timeout=5.0
            )
            
            await self.redis_client.ping()
            logger.info(f"‚úÖ Redis connect√©: {settings.redis_url}")
            self._initialized = True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur connexion Redis: {e}")
            logger.warning("‚ö†Ô∏è Mode d√©grad√©: idempotence en m√©moire uniquement")
            self.redis_client = None
            self._initialized = False
    
    async def close(self):
        """Ferme la connexion Redis."""
        if self.redis_client:
            await self.redis_client.close()
            self._initialized = False
            logger.info("‚úÖ Connexion Redis ferm√©e")
    
    async def is_webhook_processed(self, update_id: str) -> bool:
        """
        V√©rifie si un webhook update a d√©j√† √©t√© trait√©.
        
        Args:
            update_id: ID de l'update Monday.com
            
        Returns:
            True si d√©j√† trait√©, False sinon
        """
        if not self.redis_client:
            return False
        
        try:
            key = f"update:{update_id}"
            exists = await self.redis_client.exists(key)
            
            if exists:
                logger.warning(f"üö´ Webhook d√©j√† trait√©: {update_id} (Redis)")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification Redis: {e}")
            return False
    
    async def mark_webhook_processed(
        self,
        update_id: str,
        metadata: Optional[Dict[str, Any]] = None,
        ttl_seconds: int = 3600
    ) -> bool:
        """
        Marque un webhook comme trait√© dans Redis.
        
        Args:
            update_id: ID de l'update Monday.com
            metadata: M√©tadonn√©es optionnelles √† stocker
            ttl_seconds: Dur√©e de vie en secondes (d√©faut: 1h)
            
        Returns:
            True si succ√®s, False si √©chec
        """
        if not self.redis_client:
            return False
        
        try:
            key = f"update:{update_id}"
            value = json.dumps(metadata or {})
            
            await self.redis_client.setex(
                name=key,
                time=ttl_seconds,
                value=value
            )
            
            logger.debug(f"‚úÖ Webhook marqu√© trait√©: {update_id} (TTL: {ttl_seconds}s)")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur marquage Redis: {e}")
            return False
    
    async def is_event_duplicate(
        self,
        item_id: str,
        event_type: str,
        event_hash: Optional[str] = None
    ) -> bool:
        """
        V√©rifie si un √©v√©nement webhook est un doublon.
        
        Args:
            item_id: ID de l'item Monday.com
            event_type: Type d'√©v√©nement (create_update, update_column_value, etc.)
            event_hash: Hash optionnel du payload pour d√©duplication fine
            
        Returns:
            True si doublon, False sinon
        """
        if not self.redis_client:
            return False
        
        try:
            if event_hash:
                key = f"webhook:{item_id}:{event_type}:{event_hash}"
            else:
                key = f"webhook:{item_id}:{event_type}"
            
            exists = await self.redis_client.exists(key)
            
            if exists:
                logger.warning(f"üö´ √âv√©nement doublon: {item_id}/{event_type}")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification doublon Redis: {e}")
            return False
    
    async def mark_event_processed(
        self,
        item_id: str,
        event_type: str,
        event_hash: Optional[str] = None,
        ttl_seconds: int = 3600
    ) -> bool:
        """
        Marque un √©v√©nement comme trait√©.
        
        Args:
            item_id: ID de l'item Monday.com
            event_type: Type d'√©v√©nement
            event_hash: Hash optionnel du payload
            ttl_seconds: Dur√©e de vie en secondes (d√©faut: 1h)
            
        Returns:
            True si succ√®s, False si √©chec
        """
        if not self.redis_client:
            return False
        
        try:
            if event_hash:
                key = f"webhook:{item_id}:{event_type}:{event_hash}"
            else:
                key = f"webhook:{item_id}:{event_type}"
            
            await self.redis_client.setex(
                name=key,
                time=ttl_seconds,
                value="1"
            )
            
            logger.debug(f"‚úÖ √âv√©nement marqu√©: {item_id}/{event_type}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur marquage √©v√©nement Redis: {e}")
            return False
    
    async def store_context(
        self,
        task_id: int,
        context: Dict[str, Any],
        ttl_seconds: int = 3600
    ) -> bool:
        """
        Stocke un contexte court de t√¢che dans Redis.
        
        Args:
            task_id: ID de la t√¢che
            context: Contexte √† stocker
            ttl_seconds: Dur√©e de vie (d√©faut: 1h)
            
        Returns:
            True si succ√®s, False si √©chec
        """
        if not self.redis_client:
            return False
        
        try:
            key = f"context:{task_id}"
            value = json.dumps(context)
            
            await self.redis_client.setex(
                name=key,
                time=ttl_seconds,
                value=value
            )
            
            logger.debug(f"‚úÖ Contexte stock√©: task_{task_id}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur stockage contexte Redis: {e}")
            return False
    
    async def get_context(self, task_id: int) -> Optional[Dict[str, Any]]:
        """
        R√©cup√®re un contexte de t√¢che depuis Redis.
        
        Args:
            task_id: ID de la t√¢che
            
        Returns:
            Contexte si trouv√©, None sinon
        """
        if not self.redis_client:
            return None
        
        try:
            key = f"context:{task_id}"
            value = await self.redis_client.get(key)
            
            if value:
                return json.loads(value)
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration contexte Redis: {e}")
            return None
    
    def create_payload_hash(self, payload: Dict[str, Any]) -> str:
        """
        Cr√©e un hash du payload pour d√©duplication fine.
        
        Args:
            payload: Payload webhook
            
        Returns:
            Hash MD5 du payload
        """
        import hashlib
        
        key_fields = {
            "pulseId": payload.get("event", {}).get("pulseId"),
            "type": payload.get("event", {}).get("type"),
            "textBody": payload.get("event", {}).get("textBody", "")[:100],
            "columnId": payload.get("event", {}).get("columnId"),
            "value": str(payload.get("event", {}).get("value", ""))[:100]
        }
        
        payload_str = json.dumps(key_fields, sort_keys=True)
        return hashlib.md5(payload_str.encode()).hexdigest()

redis_idempotence_service = RedisIdempotenceService()

