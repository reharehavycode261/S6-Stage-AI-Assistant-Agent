"""
Agent Output Logger - Service pour logger automatiquement les inputs/outputs de l'agent dans Excel.

Flux simplifi√©:
1. Update Monday ‚Üí Agent traite
2. Agent g√©n√®re output (analyse ou PR)
3. Logger stocke automatiquement input + output dans Excel
4. Calcul de performance se fait plus tard √† partir des donn√©es Excel

Pas de feedback humain requis, juste du logging automatique.
"""

import pandas as pd
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime
from utils.logger import get_logger

logger = get_logger(__name__)


class AgentOutputLogger:
    """
    Service pour logger automatiquement les interactions de l'agent dans Excel/CSV.
    """
    
    def __init__(self, datasets_dir: Optional[Path] = None):
        """
        Initialise le logger.
        
        Args:
            datasets_dir: R√©pertoire des datasets. Par d√©faut: data/golden_datasets/
        """
        if datasets_dir is None:
            project_root = Path(__file__).parent.parent.parent
            datasets_dir = project_root / "data" / "golden_datasets"
        
        self.datasets_dir = Path(datasets_dir)
        self.datasets_dir.mkdir(parents=True, exist_ok=True)
        
        self.agent_interactions_csv = self.datasets_dir / "agent_interactions_log.csv"
        
        self._initialize_log_file()
        
        logger.info(f"‚úÖ AgentOutputLogger initialis√©: {self.agent_interactions_csv}")
    
    def _initialize_log_file(self):
        """Cr√©e le fichier CSV de log s'il n'existe pas."""
        if not self.agent_interactions_csv.exists():
            df = pd.DataFrame(columns=[
                'interaction_id',
                'timestamp',
                'monday_update_id',
                'monday_item_id',
                'interaction_type',  
                'input_text',
                'agent_output',
                'duration_seconds',
                'success',
                'error_message',
                'metadata',
                'repository_url',
                'branch_name',
                'pr_number',
                'pr_url',
                'assigned_to',
                'creator_name'
            ])
            df.to_csv(self.agent_interactions_csv, index=False)
            logger.info(f"üìÑ Fichier de log cr√©√©: {self.agent_interactions_csv}")
    
    def log_agent_interaction(
        self,
        monday_update_id: str,
        monday_item_id: str,
        input_text: str,
        agent_output: str,
        interaction_type: str,
        duration_seconds: float = 0.0,
        success: bool = True,
        error_message: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
        repository_url: Optional[str] = None,
        branch_name: Optional[str] = None,
        pr_number: Optional[str] = None,
        pr_url: Optional[str] = None,
        assigned_to: Optional[str] = None,
        creator_name: Optional[str] = None
    ) -> str:
        """
        Log une interaction de l'agent dans Excel/CSV.
        
        Args:
            monday_update_id: ID de l'update Monday qui a d√©clench√© l'agent.
            monday_item_id: ID de l'item Monday.
            input_text: Le texte d'entr√©e (question ou commande).
            agent_output: La r√©ponse g√©n√©r√©e par l'agent.
            interaction_type: Type d'interaction ('analysis' ou 'pr').
            duration_seconds: Dur√©e d'ex√©cution.
            success: Si l'interaction a r√©ussi.
            error_message: Message d'erreur si √©chec.
            metadata: M√©tadonn√©es additionnelles (dict).
            repository_url: URL du repository GitHub.
            branch_name: Nom de la branche (pour les PRs).
            pr_number: Num√©ro de la PR (pour les PRs).
            pr_url: URL de la PR (pour les PRs).
            assigned_to: Utilisateur assign√©.
            creator_name: Cr√©ateur de la t√¢che.
            
        Returns:
            interaction_id: ID unique de l'interaction logg√©e.
        """
        try:
            interaction_id = f"INT_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
            
            df_log = pd.read_csv(self.agent_interactions_csv)
            
            new_interaction = {
                'interaction_id': interaction_id,
                'timestamp': datetime.now().isoformat(),
                'monday_update_id': monday_update_id,
                'monday_item_id': monday_item_id,
                'interaction_type': interaction_type,
                'input_text': input_text,
                'agent_output': agent_output,
                'duration_seconds': round(duration_seconds, 2),
                'success': success,
                'error_message': error_message if error_message else '',
                'metadata': str(metadata) if metadata else '',
                'repository_url': repository_url if repository_url else '',
                'branch_name': branch_name if branch_name else '',
                'pr_number': pr_number if pr_number else '',
                'pr_url': pr_url if pr_url else '',
                'assigned_to': assigned_to if assigned_to else '',
                'creator_name': creator_name if creator_name else ''
            }
            
            df_log = pd.concat([df_log, pd.DataFrame([new_interaction])], ignore_index=True)
            
            df_log.to_csv(self.agent_interactions_csv, index=False)
            
            logger.info(
                f"‚úÖ Interaction logg√©e: {interaction_id} "
                f"(type={interaction_type}, success={success})"
            )
            
            return interaction_id
            
        except Exception as e:
            logger.error(f"‚ùå Erreur logging interaction: {e}", exc_info=True)
            raise
    
    def get_interactions(
        self,
        interaction_type: Optional[str] = None,
        success_only: bool = False,
        limit: Optional[int] = None,
        since_date: Optional[str] = None
    ) -> pd.DataFrame:
        """
        R√©cup√®re les interactions logg√©es avec filtres.
        
        Args:
            interaction_type: Filtrer par type ('analysis' ou 'pr').
            success_only: Ne retourner que les interactions r√©ussies.
            limit: Limiter le nombre de r√©sultats.
            since_date: Filtrer depuis une date (format: 'YYYY-MM-DD').
            
        Returns:
            DataFrame avec les interactions.
        """
        try:
            df = pd.read_csv(self.agent_interactions_csv)
            
            if interaction_type:
                df = df[df['interaction_type'] == interaction_type]
            
            if success_only:
                df = df[df['success'] == True]
            
            if since_date:
                df['date'] = pd.to_datetime(df['timestamp']).dt.date
                df = df[df['date'] >= pd.to_datetime(since_date).date()]
            
            if limit:
                df = df.tail(limit)  
            
            return df
            
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è Aucune interaction logg√©e")
            return pd.DataFrame()
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration interactions: {e}", exc_info=True)
            raise
    
    def calculate_performance_metrics(
        self,
        date: Optional[str] = None,
        save_to_metrics: bool = True
    ) -> Dict[str, Any]:
        """
        Calcule les m√©triques de performance √† partir des interactions logg√©es.
        
        Args:
            date: Date pour calculer les m√©triques (format: 'YYYY-MM-DD'). 
                  Par d√©faut: aujourd'hui.
            save_to_metrics: Si True, sauvegarde dans performance_metrics.csv.
            
        Returns:
            Dictionnaire avec les m√©triques calcul√©es.
        """
        if date is None:
            date = datetime.now().strftime("%Y-%m-%d")
        
        try:
            df = self.get_interactions(since_date=date)
            df['date'] = pd.to_datetime(df['timestamp']).dt.date
            df_day = df[df['date'] == pd.to_datetime(date).date()]
            
            if len(df_day) == 0:
                logger.warning(f"‚ö†Ô∏è Aucune interaction pour {date}")
                return {
                    'metric_date': date,
                    'total_interactions': 0,
                    'message': 'Aucune interaction ce jour'
                }
            
            total = len(df_day)
            success_count = len(df_day[df_day['success'] == True])
            failed_count = total - success_count
            
            success_rate = (success_count / total * 100) if total > 0 else 0
            avg_duration = df_day['duration_seconds'].mean()
            
            interactions_analysis = len(df_day[df_day['interaction_type'] == 'analysis'])
            interactions_pr = len(df_day[df_day['interaction_type'] == 'pr'])
            
            metrics = {
                'metric_date': date,
                'total_interactions': total,
                'interactions_analysis': interactions_analysis,
                'interactions_pr': interactions_pr,
                'success_count': success_count,
                'failed_count': failed_count,
                'success_rate_percent': round(success_rate, 1),
                'avg_duration_seconds': round(avg_duration, 2),
                'reliability_status': self._compute_reliability_status(success_rate),
                'notes': f"{failed_count} √©checs" if failed_count > 0 else "Tout OK"
            }
            
            if save_to_metrics:
                self._save_to_performance_metrics(metrics)
            
            logger.info(
                f"üìä M√©triques calcul√©es pour {date}: "
                f"{success_count}/{total} succ√®s ({success_rate:.1f}%)"
            )
            
            return metrics
            
        except Exception as e:
            logger.error(f"‚ùå Erreur calcul m√©triques: {e}", exc_info=True)
            raise
    
    def _save_to_performance_metrics(self, metrics: Dict[str, Any]):
        """Sauvegarde les m√©triques dans performance_metrics.csv."""
        try:
            metrics_file = self.datasets_dir / "performance_metrics.csv"
            
            try:
                df_metrics = pd.read_csv(metrics_file)
            except FileNotFoundError:
                df_metrics = pd.DataFrame()
            
            metric_date = metrics['metric_date']
            df_metrics = df_metrics[df_metrics['metric_date'] != metric_date]
            
            new_metric = pd.DataFrame([metrics])
            df_metrics = pd.concat([df_metrics, new_metric], ignore_index=True)
            
            df_metrics = df_metrics.sort_values('metric_date', ascending=False)
            
            df_metrics.to_csv(metrics_file, index=False)
            
            logger.info(f"‚úÖ M√©triques sauvegard√©es dans {metrics_file}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde m√©triques: {e}", exc_info=True)
    
    @staticmethod
    def _compute_reliability_status(success_rate: float) -> str:
        """Calcule le statut de fiabilit√© bas√© sur le taux de succ√®s."""
        if success_rate >= 95:
            return "excellent"
        elif success_rate >= 85:
            return "good"
        elif success_rate >= 70:
            return "acceptable"
        else:
            return "needs_improvement"
    
    def get_statistics_summary(self, days: int = 7) -> Dict[str, Any]:
        """
        G√©n√®re un r√©sum√© statistique sur les N derniers jours.
        
        Args:
            days: Nombre de jours √† analyser.
            
        Returns:
            Dictionnaire avec statistiques globales.
        """
        try:
            start_date = (datetime.now() - pd.Timedelta(days=days)).strftime("%Y-%m-%d")
            
            df = self.get_interactions(since_date=start_date)
            
            if df.empty:
                return {"message": f"Aucune interaction dans les {days} derniers jours"}
            
            total = len(df)
            success = len(df[df['success'] == True])
            failed = total - success
            
            summary = {
                "period_days": days,
                "start_date": start_date,
                "end_date": datetime.now().strftime("%Y-%m-%d"),
                "total_interactions": total,
                "success_count": success,
                "failed_count": failed,
                "success_rate": round((success / total * 100), 1) if total > 0 else 0,
                "interactions_analysis": len(df[df['interaction_type'] == 'analysis']),
                "interactions_pr": len(df[df['interaction_type'] == 'pr']),
                "avg_duration_seconds": round(df['duration_seconds'].mean(), 2),
                "total_duration_hours": round(df['duration_seconds'].sum() / 3600, 2)
            }
            
            return summary
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration statistiques: {e}", exc_info=True)
            return {"error": str(e)}
    
    def export_to_excel(self, output_file: Optional[Path] = None):
        """
        Exporte toutes les interactions vers un fichier Excel avec formatage.
        
        Args:
            output_file: Chemin du fichier de sortie. 
                        Par d√©faut: agent_interactions_export.xlsx
        """
        try:
            if output_file is None:
                output_file = self.datasets_dir / "agent_interactions_export.xlsx"
            
            df = pd.read_csv(self.agent_interactions_csv)
            
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='Interactions', index=False)
            
            logger.info(f"‚úÖ Export Excel cr√©√©: {output_file} ({len(df)} interactions)")
            
            return str(output_file)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur export Excel: {e}", exc_info=True)
            raise

