#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Convertit golden_sets_10_exemples.csv en golden_sets.csv utilisable

Ajoute les colonnes manquantes :
- input â†’ transformÃ© en updateMday_XXX
- output â†’ gardÃ© tel quel
- type â†’ dÃ©tectÃ© automatiquement (analysis/pr)
"""

import pandas as pd
from pathlib import Path
import re
import csv


def detecter_type(input_text: str, output_text: str) -> str:
    """DÃ©tecte si c'est une analyse ou une PR"""
    
    # Mots-clÃ©s pour PR
    pr_keywords = ['pr #', 'pull request', 'branche', 'commit', 'merge', 'crÃ©Ã©e avec succÃ¨s']
    
    input_lower = input_text.lower()
    output_lower = output_text.lower()
    
    # Si input demande crÃ©ation/implÃ©mentation ET output mentionne PR
    if any(keyword in output_lower for keyword in pr_keywords):
        return 'pr'
    
    # Si input demande crÃ©ation/implÃ©mentation mais output est explicatif
    creation_keywords = ['crÃ©e', 'implÃ©mente', 'ajoute', 'gÃ©nÃ¨re', 'dÃ©veloppe']
    if any(keyword in input_lower for keyword in creation_keywords):
        # Si output explique comment faire â†’ analysis
        # Si output dit qu'une PR a Ã©tÃ© crÃ©Ã©e â†’ pr
        if 'pr #' in output_lower or 'crÃ©Ã©e' in output_lower:
            return 'pr'
        else:
            return 'analysis'  # C'est une explication de comment faire
    
    # Par dÃ©faut, c'est une analysis
    return 'analysis'


def main():
    print("\n" + "="*70)
    print("ğŸ”„ CONVERSION: golden_sets_10_exemples.csv â†’ golden_sets.csv")
    print("="*70)
    
    # Chemins
    base_path = Path(__file__).parent.parent / "data/golden_datasets"
    input_file = base_path / "golden_sets_10_exemples.csv"
    output_file = base_path / "golden_sets.csv"
    
    # Ã‰TAPE 1: Compter le nombre total de lignes du fichier
    print(f"\nğŸ“Š VÃ©rification du fichier source...")
    with open(input_file, 'r', encoding='utf-8') as f:
        total_lines = sum(1 for line in f if line.strip())  # Ignorer les lignes complÃ¨tement vides
    
    print(f"   Lignes totales (non vides): {total_lines}")
    
    # Ã‰TAPE 2: Lire le fichier source avec gestion d'erreurs
    print(f"\nğŸ“‚ Lecture de {input_file.name}...")
    
    rows = []
    ignored_count = 0
    parse_errors = []
    
    with open(input_file, 'r', encoding='utf-8') as f:
        csv_reader = csv.reader(f, quotechar='"', doublequote=True)
        for line_num, row in enumerate(csv_reader, 1):
            try:
                if len(row) >= 2:
                    # Prendre les 2 premiÃ¨res colonnes
                    input_text = row[0].strip()
                    output_text = row[1].strip()
                    
                    # VÃ©rifier que ce ne sont pas des lignes vides
                    if input_text and output_text:
                        rows.append({
                            'input_text': input_text, 
                            'output_reference': output_text,
                            'line_number': line_num
                        })
                    else:
                        ignored_count += 1
                elif len(row) == 1:
                    # Ligne incomplÃ¨te
                    if row[0].strip():
                        parse_errors.append(f"Ligne {line_num}: incomplÃ¨te - {row[0][:50]}...")
                    ignored_count += 1
                elif len(row) == 0:
                    # Ligne vide
                    ignored_count += 1
                # Les lignes complÃ¨tement vides sont ignorÃ©es silencieusement
            except Exception as e:
                parse_errors.append(f"Ligne {line_num}: erreur de parsing - {str(e)}")
                ignored_count += 1
    
    df = pd.DataFrame(rows)
    loaded_count = len(df)
    
    # Ã‰TAPE 3: VÃ©rifier la cohÃ©rence
    print(f"\nâœ… {loaded_count} exemples chargÃ©s")
    
    if ignored_count > 0:
        print(f"   âš ï¸  {ignored_count} lignes ignorÃ©es (incomplÃ¨tes ou vides)")
    
    if parse_errors:
        print(f"\nâš ï¸  Erreurs de parsing dÃ©tectÃ©es:")
        for error in parse_errors[:5]:  # Montrer les 5 premiÃ¨res
            print(f"   â€¢ {error}")
        if len(parse_errors) > 5:
            print(f"   ... et {len(parse_errors) - 5} autres erreurs")
    
    # Ã‰TAPE 4: Alerte si diffÃ©rence importante
    expected_valid = total_lines  # On s'attend Ã  charger toutes les lignes non vides
    difference = expected_valid - loaded_count - ignored_count
    
    if difference > 5:  # Seuil de tolÃ©rance
        print(f"\nâš ï¸  ATTENTION: DiffÃ©rence importante dÃ©tectÃ©e!")
        print(f"   Lignes totales: {total_lines}")
        print(f"   Lignes chargÃ©es: {loaded_count}")
        print(f"   Lignes ignorÃ©es: {ignored_count}")
        print(f"   DiffÃ©rence: {difference}")
        print(f"\n   â†’ VÃ©rifiez le format du CSV (guillemets, virgules, etc.)")
    else:
        print(f"\nâœ… VÃ©rification OK: {loaded_count} lignes valides sur {total_lines} total")
    
    # Transformer en format golden_sets
    print("\nğŸ”„ Transformation en cours...")
    
    golden_rows = []
    for idx, row in df.iterrows():
        input_text = row['input_text']
        output_text = row['output_reference']
        
        # CrÃ©er un ID Monday fictif mais cohÃ©rent
        # Utiliser l'index + un prÃ©fixe
        monday_id = f"golden_{idx+1:04d}"
        input_id = f"updateMday_{monday_id}"
        
        # DÃ©tecter le type
        item_type = detecter_type(input_text, output_text)
        
        golden_rows.append({
            'input': input_id,
            'output': output_text,
            'type': item_type,
            'input_text_original': input_text  # Pour rÃ©fÃ©rence
        })
    
    # CrÃ©er le DataFrame final
    df_golden = pd.DataFrame(golden_rows)
    
    # Statistiques
    print(f"\nğŸ“Š Statistiques:")
    print(f"   Total: {len(df_golden)} entrÃ©es")
    
    type_counts = df_golden['type'].value_counts()
    for type_name, count in type_counts.items():
        percentage = (count / len(df_golden) * 100)
        print(f"   â€¢ {type_name}: {count} ({percentage:.1f}%)")
    
    # AperÃ§u
    print(f"\nğŸ“ AperÃ§u des premiÃ¨res entrÃ©es:")
    for i in range(min(3, len(df_golden))):
        row = df_golden.iloc[i]
        print(f"\n   {i+1}. Input ID: {row['input']}")
        print(f"      Type: {row['type']}")
        print(f"      Question: {row['input_text_original'][:60]}...")
        print(f"      Output: {row['output'][:80]}...")
    
    # Sauvegarder
    print(f"\nğŸ’¾ Sauvegarde...")
    
    # Version simple (input, output, type)
    df_golden_simple = df_golden[['input', 'output', 'type']]
    df_golden_simple.to_csv(output_file, index=False)
    print(f"âœ… Golden Set sauvegardÃ©: {output_file}")
    
    # Version dÃ©taillÃ©e
    output_file_detailed = base_path / "golden_sets_detailed.csv"
    df_golden.to_csv(output_file_detailed, index=False)
    print(f"âœ… Version dÃ©taillÃ©e: {output_file_detailed}")
    
    print("\n" + "="*70)
    print("âœ… Conversion terminÃ©e !")
    print("="*70)
    
    print("\nğŸ’¡ Prochaines Ã©tapes:")
    print("   1. Le fichier golden_sets.csv contient maintenant vos 92 exemples")
    print("   2. Ces outputs sont les RÃ‰FÃ‰RENCES PARFAITES attendues")
    print("   3. Lancer l'Ã©valuation pour comparer agent vs rÃ©fÃ©rences")
    print("   4. python scripts/evaluation_finale_golden_set.py")
    
    print("\nâš ï¸  IMPORTANT:")
    print("   Les inputs ont des IDs fictifs (updateMday_golden_XXXX)")
    print("   Pour utiliser les vrais IDs Monday, vous devez les mapper manuellement")
    print("   dans golden_sets.csv")


if __name__ == "__main__":
    main()

